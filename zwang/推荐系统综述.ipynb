{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abfc8dd5",
   "metadata": {},
   "source": [
    "# 推荐系统\n",
    "\n",
    "推荐系统会根据用户过去的点击、点赞、收藏、转发、评论等行为给用户推荐可能感兴趣的笔记，把一篇笔记展示给用户叫做曝光impression, 假如用户对这篇笔记感兴趣，会点击它，进入这篇笔记，如果用户在这篇笔记上停留几秒，意味着用户不是手滑，而是真的对这篇笔记感兴趣，这被算作一次有效点击，有效点击就意味着用户对笔记感兴趣，这将作为推荐系统的一个信号。接下来用户可能会向下滑动，阅读这篇笔记，如果滑动到底，更能说明用户对这篇笔记感兴趣，滑动到底也是推荐系统的一个依据；如果用户足够喜欢这篇笔记，可能还会点赞、收藏、转发。\n",
    "\n",
    "转化流程：推荐系统决定给用户曝光什么内容 (Impression) -> 用户自己决定是否点击进去 (Click) -> 点击进去是否会滑动到底 (ScrollToEnd) (-> 评论 (Comment)) 、点赞 （Like）、 收藏 (Collect) 、转发 (Share)。不同的网站、手机App都会有不同的转化流程，跟产品的设计有关，算法工程师应该熟悉自己公司的产品，这对设计特征和模型会有帮助。对于绝大多数的产品，前两步都是曝光 -> 点击，比如YouTube、B站、淘宝、快手、知乎都是这种设计，但是抖音不太一样，抖音没有曝光和点击，用户下滑一次只能看到一个视频。点击之后，用户会做这几个动作，包括滑动到底、点赞、收藏、转发，这些动作意味着用户对笔记感兴趣，这些动作都可以作为推荐系统利用的信号，推荐的依据。在滑动到底之后，用户可以留评论，正面和衷心的评论对社区的氛围很有好处，所以留评论也会作为推荐系统的一个信号。\n",
    "\n",
    "作为算法工程师，我们优化推荐系统是为了提升一些业务指标。这些指标反映出用户对推荐是否满意。\n",
    "\n",
    "消费指标：\n",
    "\n",
    "* 点击率 = 点击次数 ／ 曝光次数\n",
    "    \n",
    "    点击率是个重要的消费指标，点击率越高，说明推荐越精准，给用户展示了他感兴趣的内容。虽然点击率是重要的消费指标，但也不能把点击率作为唯一的优化目标，否则骗点击的标题就会泛滥，到处都是美国人吓尿了，日本人震惊了，或者满屏都是美女图片骗点击，其他一些指标也可以反映出用户对笔记的兴趣。\n",
    "\n",
    "* 点赞率 = 点赞次数 ／ 点击次数\n",
    "\n",
    "* 收藏率 = 收藏次数 ／ 点击次数\n",
    "\n",
    "* 转发率 = 转发次数 ／ 点击次数\n",
    "\n",
    "* 阅读完成率 = 滑动到底次数 ／ 点击次数 * f(笔记长度)\n",
    "\n",
    "    f()是一个归一化的函数，笔记越长，完成阅读的比例就越低，如果没有归一化的函数，对长笔记会不公平。通常来说，推荐的笔记越符合用户兴趣，那么点击、点赞等行为就会越多。做实验的时候，希望看到新的推荐算法能够在这些指标上超越原有的算法。\n",
    "\n",
    "这些短期消费指标都是有意义的，但它们不是衡量推荐系统好坏的根本指标，一味追求这些短期消费指标是不对的。如果推荐算法只看用户短期兴趣，推很多用户最近感兴趣的内容，会让这些消费指标上涨，但这样的坏处是会竭泽而渔，用户很快就会失去兴趣，不再活跃。反过来，如果把多样性做好，尝试一些用户没看过的话题，那么点击率不会上涨，但会有利于提高用户粘性，留住用户，让用户更活跃。\n",
    "\n",
    "短期消费指标不是最重要的指标，衡量推荐系统好坏，最重要的指标是北极星指标：用户规模、消费、发布，北极星指标意思就是最关键的指标，是衡量推荐系统好坏的根本标准。\n",
    "\n",
    "* 用户规模：\n",
    "    \n",
    "    用日活用户(DAU)、月活用户(MAU)来衡量。一个用户今天使用1次app或者使用10次app，今天都算给app贡献了1个DAU，在这个月，不论是只登陆了1次app还是每天都登陆app，都算给app贡献了一个MAU。DAU、MAU都跟推荐系统的好坏强相关，推荐系统做的好，用户就会越活跃，DAU和MAU就会越高。\n",
    "\n",
    "* 消费：\n",
    "\n",
    "    包括人均使用推荐的时长、人均阅读笔记的数量。如果今天刷了1h推荐，那么就贡献了1h时长，如果今天看了20篇笔记，就贡献了20篇笔记阅读量，推荐做的越好，用户就会越上瘾，使用app的时长和阅读数量就会越高。这两个指标比点击率、点赞率更能反映推荐做的好不好。通常来说，点击率跟时长、阅读数量的涨跌是一致的，万一有冲突，要以北极星指标为准。比如，把推荐系统的多样性做好，探索用户的兴趣，使得用户使用的时长增长，但是点击率下跌了，这完全OK，这样的策略应该上线，北极星指标比点击率更重要。\n",
    "\n",
    "* 发布：\n",
    "    包括发布渗透率、人均发布量。希望推荐系统能激励作者发布，让内容池变大，优质内容池是核心竞争力。激励发布通常是由冷启动来负责。\n",
    "\n",
    "算法工程师的工作就是对模型、特征、策略、系统做改进，提升各种指标，对推荐系统的改动能不能最终上线，要拿实验结果来说话。实验流程是先做离线实验，好的话，上线做小流量AB测试，表现好的话加大流量，最终目的是全流量上线。\n",
    "\n",
    "离线实验：用收集的历史数据做训练和测试，做离线实验不需要把算法部署到产品中，没有跟用户实际交互，因此离线实验很容易做，不需要占用线上流量，也不会对系统和用户产生负面影响，有很多评价离线实验的指标。离线实验的结果有参考价值，能大致反映出算法的好坏，但是离线实验并没有线上实验可靠。\n",
    "\n",
    "小流量AB测试：想最终判断算法的好坏，还是需要做线上实验，前面提到的北极星指标都是线上指标，只能通过线上实验获得，做离线实验无法得到这些指标。具体做法是开小流量AB测试，把用户随机分为实验组和对照组，实验组用新策略，对照组用旧策略，对比两者的业务指标，判断新策略是否会显著优于旧策略，如果新策略显著优于旧策略，可以加大流量，最终推全流量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18691031",
   "metadata": {},
   "source": [
    "## 推荐系统的链路\n",
    "\n",
    "推荐系统的目标是从物品的数据库中选出几十个物品展示给用户，推荐系统的链路分为召回、粗排、精排、重排。整条链路上，召回和粗排是最大的漏斗，它们让候选笔记的数量从几亿到几千，然后变成几百，当候选笔记只有几百篇时，才能够用大规模的神经网络做精排，才能用DPP这样的方法做多样性抽样，如果笔记的数量太大，就不可能用大规模神经网络和DPP。\n",
    "\n",
    "* 召回\n",
    "\n",
    "    推荐系统链路上的第一环是召回，就是从物品的数据库中快速取回一些物品，比如某app有亿篇笔记，当用户刷新app时，系统会同时调用几十条召回通道，每条召回通道会取回几十到几百篇笔记，一共取回几千篇笔记。\n",
    "\n",
    "    在实践中，推荐系统有很多召回通道，常见的包括协同过滤、双塔模型、关注的作者等等。比如某app有几十个通道，每隔召回通道取回几十到几百篇笔记，这些召回通道一共会反悔几千篇笔记，然后推荐系统会融合这些笔记，并且做去重和过滤，过滤是排除掉用户不喜欢的作者、不喜欢的话题、不喜欢的笔记。\n",
    "\n",
    "召回几千篇笔记之后，下一步是排序，排序要用机器学习模型预估用户对笔记的兴趣，保留分数最高的笔记。如果直接用大规模神经网络对几千篇笔记逐一打分，花费的代价会很大，为了解决计算量的问题，通常把排序分为粗排和精排两步。\n",
    "\n",
    "* 粗排\n",
    "\n",
    "    做完召回之后，接下来要从几千篇笔记中选出用户最感兴趣的，下一步是粗排，用规模比较小的机器学习模型，快速对几千篇笔记逐一打分，按照分数做排序和截断，保留分数最高的几百篇笔记，送入精排，当然这里也会用一些规则，保证进入精排的笔记具有多样性。\n",
    "\n",
    "* 精排\n",
    "\n",
    "    这里要用大规模的深度神经网络，对几百篇笔记逐一打分，精排的分数反映出用户对笔记的兴趣，在精排之后可以做截断也可以不做截断。如果不做截断，所有这几百篇笔记带着分数进入重排。\n",
    "\n",
    "    粗排和精排非常相似，差别是精排模型比粗排模型大很多，用的特征也更多，所以精排打的分数更可靠，但是精排的计算量很大，这就是为什么先要用粗排做筛选，然后采用精排，这样可以比较好的平衡计算量和准确性。做完粗排和精排，得到几百篇笔记，每篇笔记有一个分数，表示用户对笔记的兴趣有多高，可以直接把笔记按照模型打的分数做排序，然后展示给用户，但此时的结果还存在一些不足，需要做一些调整，这一步叫做重排。 \n",
    "\n",
    "* 重排\n",
    "\n",
    "    重排是最后一步，这里会根据精排分数和多样性分数做随机抽样，得到几十篇笔记，然后把相似内容打散，并且插入广告和运营内容。 \n",
    "\n",
    "    重排主要是考虑多样性，要根据多样性做随机抽样，从几百篇笔记中选出几十篇，然后还要用规则把内容相似的笔记打散，重排的结果就是最终要展示给用户的物品，比如把前80的物品展示给用户，其中包括笔记和广告。\n",
    "\n",
    "### 粗排、精排\n",
    "\n",
    "模型输入包括用户特征、候选物品的特征、统计特征，假如需要判断一个用户是否对一篇笔记感兴趣，就要把三类特征输入神经网络，神经网络的结构各种各样，神经网络会输出很多数值，比如点击率、点赞率、收藏率、转发率，这些数值都是神经网络对用户行为的预估，这些数值越大说明用户对笔记越感兴趣。最后把多个预估值做融合，比如求加权和，得到最终的排序分数，这个分数决定了这个笔记会不会被展示给用户，以及笔记展示的位置是靠前还是靠后。这只是对一篇笔记的打分，粗排要对几千篇笔记打分，精排要对几百篇笔记打分，每篇笔记都有多个预估分数，融合成一个分数，作为给这篇笔记排序的依据。\n",
    "\n",
    "### 重排\n",
    "\n",
    "推荐系统链路上的最后一环是重排，重排最重要的功能是多样性抽样，比如MMR、DPP，需要从几百篇笔记中选出几十篇；\n",
    "\n",
    "抽样的时候有两个依据：一个是精排分数的大小，一个是多样性。\n",
    "\n",
    "做完抽样之后，会用规则打散相似笔记，不能把内容过于相似的笔记排在相邻的位置上。比如根据精排的分数，排名前5的笔记都是NBA的内容，这样就不太合适，即使用户是个篮球迷，他也未必希望看到同质化的内容，如果排第一的是NBA的笔记，那么接下来几个位置就不能放NBA的内容，相似的笔记会往后放。\n",
    "\n",
    "重排的另一个目的是插入广告、运营推广内容，还要根据生态的要求调整排序，比如不能连着出很多美女图片。\n",
    "\n",
    "重排的规则非常复杂，有好几千行代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afaf16",
   "metadata": {},
   "source": [
    "# 召回\n",
    "\n",
    "## 协同过滤\n",
    "\n",
    "### 基于物品的协同过滤 (ItemCF)\n",
    "\n",
    "ItemCF原理：\n",
    "\n",
    "比如系统通过历史记录可以知道某用户喜欢看《笑傲江湖》，《笑傲江湖》与《鹿鼎记》相似，而且用户没有看过《鹿鼎记》，那么系统会给用户推荐《鹿鼎记》，推荐的理由是两个物品很相似。\n",
    "\n",
    "推荐系统如何知道《笑傲江湖》和《鹿鼎记》相似？有很多办法可以做到，比如用知识图谱，两本书的作者相同，所以两本书相似；还可以基于全体用户的行为，判断两个物品的相似性。比如看过《笑傲江湖》的用户也看过《鹿鼎记》、给《笑傲江湖》写好评的用户也给《鹿鼎记》写好评，可以从用户的行为中挖掘出物品的相似性，再利用物品之间的相似性做推荐。\n",
    "\n",
    "ItemCF的实现：\n",
    "\n",
    "每个用户都交互过若干物品，比如点击、点赞、收藏、转发过的物品，可以量化用户对物品的兴趣 like(user, item)，比如点击、点赞、收藏、转发四种行为各算1分，或者分数分别是(2, 1, 4, 3)。对于用户没有交互过的候选物品，我们要决定是否把这个物品推荐给用户，假设我们知道物品两两之间的相似度 $sim(item_j, item)$，比如它们之间的相似度分别是(0.1, 0.4, 0.2, 0.6), 然后预估用户对候选物品的兴趣 $\\sum_{j} like(user, item) \\cdot sim(item_j, item)$, 在这个例子中，从用户到候选物品有4条路径，所以要计算4个分数，然后把它们相加，$2x0.1+1x0.4+4x0.2+3x0.6=3.2$, 表示用户对候选物品的兴趣。假如有2000个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回其中分数最高的100个物品。\n",
    "\n",
    "物品的相似度：\n",
    "\n",
    "计算物品相似度的基本想法是：两个物品的受众重合度越高，两个物品就越相似。我们可以从数据中挖掘出两个物品的相似度。例如，喜欢《射雕英雄传》和《神雕侠侣》的读者重合度很高，因此可以认为两个作品相似。注意，这里不是通过物品的内容判定相似，而是通过用户的行为判定相似。\n",
    "\n",
    "* 喜欢物品$i_1$的用户记作集合$w_1$\n",
    "* 喜欢物品$i_2$的用户记作集合$w_2$\n",
    "* 定义交集$v = w_1 \\mid w_2$， $v$包含同时喜欢物品$i_1, i_2$的用户\n",
    "* 计算两个物品的相似度：\n",
    "\n",
    "$$sim(i_1, i_2) = \\frac{|v|}{\\sqrt{|w_1| \\cdot |w_2|}}$$\n",
    "\n",
    "相似度介于（0，1），值越大表示两个物品越相似。注意，这个公式没有考虑用户对物品喜欢的程度 $like(user, item)$, 用这个公式，只要是喜欢就看作1，不喜欢就看作0，如果想要用到喜欢的程度，需要改一下这个公式，比如点击、点赞、收藏、转发各自算1分，用户对物品的喜欢程度最多可以是4分。公式改为：\n",
    "\n",
    "$$im(i_1, i_2) = \\frac{\\sum_{v \\in V} like(v, i_1) \\cdot like(v, i_2)}{\\sqrt{\\sum_{u_1 \\in w_1} like^2(u_1, i_1)} \\cdot \\sqrt{\\sum_{u_2 \\in w_2} like^2(u_2, i_2)}}$$\n",
    "\n",
    "如果分子的兴趣分数取值是0或者1，那么分子就是同时喜欢两个物品的人数，也就是集合v的大小。\n",
    "\n",
    "这个分数计算的数值也是介于（0，1），表示两个物品的相似度，其实就是余弦相似度，把一个物品表示为1个稀疏向量，向量每个元素对应1个用户，元素的值就是用户对物品的兴趣分数，两个向量的夹角的余弦就是这个公式。\n",
    "\n",
    "总结：\n",
    "\n",
    "ItemCF的基本思想是根据物品的相似度做推荐，如果某个用户喜欢物品1，而且物品1和物品2相似，那么该用户很可能会喜欢物品2，做推荐就是要预估用户对候选物品的兴趣有多强，给每一个物品打一个分数，把分数高的物品推荐给用户。可以这样理解，用户对物品1感兴趣，兴趣传递到候选物品，得到用户对候选物品的兴趣分数。有很多条这样的路径，把兴趣从用户传递到物品j，再传递到候选物品，把这些路径全都加起来，就是用户对候选物品的兴趣分数。需要事先计算每两个物品之间的相似度，并且保存起来。\n",
    "\n",
    "ItemCF用于召回的完整流程：\n",
    "\n",
    "为了能在线上做到实时的推荐，系统必须要事先做离线计算，建立两个索引，一个索引是“用户 -> 物品”，索引记录每个用户最近点击过、交互过的物品ID，比如最近交互过的200个物品，有了这个索引之后，给定任意用户ID，可以快速返回他最近感兴趣点物品列表；另一个索引是“物品 -> 物品”，首先要计算物品之间两两相似度，这个计算量会比较大，对于每个物品，索引它最相似的k个物品，比如k=10或者100，有了这个索引之后，给定任意物品ID，可以快速查出它最相似的k个物品ID，而且知道相似度分数。\n",
    "\n",
    "“用户 -> 物品”索引：\n",
    "\n",
    "用户ID： （物品ID，兴趣分数）的列表。记录每个用户最近点击、交互过的物品ID，每个物品还有一个兴趣分数，比如点击、点赞、收藏、转发各算1分，相加就是用户对物品的兴趣分数。\n",
    "\n",
    "“物品 -> 物品”索引：\n",
    "\n",
    "物品ID：最相似的k个物品的（ID，相似度）列表。列表中相似度从高到低排列。\n",
    "\n",
    "线上做召回：\n",
    "\n",
    "有了索引之后，我们可以在线上给用户做实时推荐，比如有个用户在刷app，系统要给用户做推荐，系统知道这个用户的ID，首先查看用户->物品的索引，可以快速找到这个用户近期感兴趣的物品列表，把用户最近交互过的物品叫做last-n，对于last-n集合中的每个物品，我们利用物品->物品的索引，找到top-k相似物品，用户最近有n个感兴趣的物品，那么一共取回nk个物品，对于取回的nk个相似物品，用公式预估用户对物品的兴趣分数，做计算时用到用户对物品的兴趣分数、物品和物品的相似度分数，把兴趣分数和相似度分数相乘，如果取回的物品ID有重复的，就去重把分数加起来，按照分数从高到低对物品做排序，返回分数最高的100个物品，就是ItemCF这个召回通道的输出，会跟其他召回通道的输出融合起来，然后做排序，最终展示给用户。\n",
    "\n",
    "为什么要用索引呢？\n",
    "\n",
    "数据库中有上亿个物品，如果挨个用公式计算用户对所有物品的兴趣分数，计算量会爆，索引的意义在于避免枚举所有的物品。假如我们记录用户最近感兴趣的n=200个物品，取回每个物品最相似的k=10个物品，一共取回nk=2000个物品，用公式给2000个物品打分，也就是分别预估用户对2000个物品的兴趣分数，返回分数最高的100个物品作为ItemCF这个召回通道的结果，这样的计算量是很小的，可以做到在线实时计算。总结一下，用索引的话，离线计算量大，需要更新2个索引，好处是在线计算量小，每次做召回都很快，只需要给2000个物品打分，不需要访问上亿个物品。\n",
    "\n",
    "在工业界的推荐系统中，ItemCF是最重要的召回通道之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f6d19",
   "metadata": {},
   "source": [
    "### Swing 召回通道\n",
    "Swing是ItemCF的一个变体，在工业界很常用，与ItemCF唯一的区别是怎么定义物品的相似度。 \n",
    "\n",
    "ItemCF计算两个物品相似度的原理通常来说是有道理的，如果大量的用户同时喜欢两个物品，那么这两个物品应该有某种共性，比方说左边是骂川普的文章，右边是支持绿色能源的文章，两篇文章字面上没啥相似性，但是用ItemCF会发现两者之间的相似度会非常高，这是有道理的，如果一个用户喜欢看支持绿色能源的文章，如果给他推骂川普的文章，他也很有可能会点击或点赞。举个反例，一篇文章骂川普，一篇文章支持川普，两篇文章字面上特别像，但是ItemCF会发现两篇文章的相似度会非常低，给支持川普的文章点赞的不可能给骂川普的文章点赞。\n",
    "\n",
    "ItemCF的不足之处：计算物品的相似度时，假如重合的用户是一个小圈子，比如都在一个微信群里，左边是《某网站护肤品打折》的笔记，右边是《字节裁员了》笔记，这两篇笔记没有相似之处，它们的受众差别很大，但是两篇笔记碰巧被分享到同一个群里，群里有很多人都点击了这两篇笔记，这样就造成了一个问题，两篇笔记的受众完全不同，但是很多用户同时交互了这两篇笔记，导致系统错误地判断两篇笔记的相似度很高，想要解决这个问题，需要降低小圈子用户的权重，我们希望两个物品重合的用户广泛而且多样，而不是集中在一个小圈子里，一个小圈子的用户同时交互两个物品，不能说明两个物品相似。反过来，如果大量不相关的用户同时交互两个物品，则说明两个物品有相同的受众。Swing模型的原理，就是给用户设置权重，解决小圈子问题。\n",
    "\n",
    "Swing模型：\n",
    "\n",
    "* 用户$u_1$喜欢的物品记作集合$J_1$\n",
    "* 用户$u_2$喜欢的物品记作集合$J_2$\n",
    "* 定义两个用户的重合度：$overlap(u_1, u_2) = \\mid J_1 \\cap J_2 \\mid$\n",
    "* 用户$u_1$和$u_2$的重合度高，则他们可能来自一个小圈子，要降低他们的权重，在计算物品相似度的时候，会把$overlap(u_1, u_2)$放到分母上。\n",
    "\n",
    "* 喜欢物品$i_1$的用户记作集合$w_1$\n",
    "* 喜欢物品$i_2$的用户记作集合$w_2$\n",
    "* 定义交集$v = w_1 \\mid w_2$\n",
    "* 计算两个物品的相似度：\n",
    "\n",
    "$$sim(i_1, i_2) = \\sum_{u_1 \\in v} \\sum_{u_2 \\in v} \\frac{1}{\\alpha + overlap(u_1 + u_2)}$$\n",
    "\n",
    "$\\alpha$是个人工设置的参数，需要调，overlap是用户$u_1, u_2$的重叠有多大，重叠大说明两个人是一个小圈子的，他们两个人对相似度的贡献会比较小，反过来，如果overlap小，那他们的相似度贡献比较大，用overlap可以降低小圈子对相似度的影响。\n",
    "\n",
    "ItemCF考察两个物品重合的受众比例有多高，如果很多用户同时喜欢两个物品，则判定两个物品相似；Swing跟ItemCF差不多，但是会额外考虑重合的用户是否来自同一个小圈子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ad4f9",
   "metadata": {},
   "source": [
    "### 基于用户的协同过滤（UserCF）\n",
    "\n",
    "ItemCF是基于物品之间的相似性做推荐，UserCF是基于用户之间的相似性做推荐。\n",
    "\n",
    "UserCF的原理：\n",
    "\n",
    "1. 有很多跟我兴趣非常相似的网友；\n",
    "2. 其中某个网友对某笔记点赞、转发\n",
    "3. 我没看过这篇笔记\n",
    "\n",
    "    ======>\n",
    "    \n",
    "     推荐系统给我推荐这篇笔记\n",
    "\n",
    "推荐系统如何找到跟我兴趣非常相似的网友？\n",
    "\n",
    "方法一：判断两个人感兴趣的笔记有多少重合，每个用户都有一个列表，上面存储了点击、点赞、收藏、转发的笔记ID，对比两个用户的列表，就知道有多大的重合，重合越多，说明两个人的兴趣越相似。\n",
    "\n",
    "方法二：不是看笔记重合，而是看作者的重合，每个用户都会关注一些作者，对比两个用户关注的作者列表，就知道有多少关注的作者是重合的，专注的作者重合越多，说明两个人的兴趣越相似。\n",
    "\n",
    "UserCF的实现：\n",
    "\n",
    "在用UserCF做推荐之前，需要先离线算好每两个用户之间的相似度$sim(user, user_j)$。例如，我们想要给左边的用户做推荐，中间是最相似的4个用户，(0.9, 0.7, 0.7, 0.4)分别表示用户之间的相似度$sim(user, user_j)$，数值越大，表示用户越相似，右边是候选物品，左边的用户还没有看过这个候选物品，我们想要预估左边的用户对右边候选物品的兴趣有多大 $like(user, item)$，历史的数据反映了中间的用户和候选物品的兴趣，比如点击、点赞、收藏、转发4种行为各算1分，4个用户对候选物品的分数分别是(0, 1, 3, 0), 分数越大，表示用户对物品越感兴趣，0表示用户没有看过物品或者对物品不感兴趣，用这个公式$\\sum_j{sim(user, user_j) \\cdot like(user_j, item)}$来预估用户对候选物品的兴趣, 把相似度和兴趣分数相乘，再把所有的乘积都加起来得到总分，表示用户对候选物品的兴趣。在这个例子中，从左边的用户到右边的候选物品有4条路径，所以要计算4个分数，然后把它们相加，$0.9x0+0.7x1+0.4x3+0.4x0=2.8$。假如有2000个候选物品，我们逐一计算用户对候选物品的分数，然后返回其中分数最高的100个物品。\n",
    "\n",
    "用户相似度，指的是用户有共同的兴趣点：\n",
    "\n",
    "* 用户$u_1$喜欢的物品记作集合$J_1$\n",
    "* 用户$u_2$喜欢的物品记作集合$J_2$\n",
    "* 定义交集$I = J_1 \\cap J_2$，包含两个用户共同喜欢的物品\n",
    "* 两个用户的相似度：\n",
    "\n",
    "    $$sim(u_1, u_2) = \\frac{\\mid I \\mid}{\\sqrt{\\mid J_1 \\mid \\cdot \\mid J_2 \\mid}}$$\n",
    "\n",
    "    相似度是介于（0，1）之间的值，数值越接近1，表示两个用户越相似。\n",
    "\n",
    "这个公式有个不足之处，公式同等对待热门和冷门的物品，这是不对的，拿书籍推荐举个例子，《哈利波特》是非常热门的物品，所有人喜欢看《哈利波特》，那它对计算用户相似度是没有价值的，越热门的物品越无法反映出用户独特的兴趣，对计算相似度就没有用，反过来，重合的物品越冷门，越能反映出用户的兴趣，如果两个用户都喜欢《Deep Learning》这本书，说明两个人很可能是同行，如果两个用户都喜欢一些更冷门的书，比如《深度学习在语音识别中的应用》，说明两个人是小同行。为了更好计算用户兴趣的相似度，我们需要降低热门物品的权重。\n",
    "\n",
    "* 上面计算两个用户相似度公式可以等价改写为：\n",
    "    \n",
    "    $$sim(u_1, u_2) = \\frac{\\sum_{l \\in I} 1}{\\sqrt{\\mid J_1 \\mid \\cdot \\mid J_2 \\mid}}$$\n",
    "\n",
    "    分子中，不论冷门、热门，物品权重都是1。\n",
    "    \n",
    "物品的重要性应该与物品的热门程度相关，越热门的物品，权重应该越低，将上式分子改进后的两个用户的相似度为：\n",
    "    \n",
    "$$sim(u_1, u_2) = \\frac{\\sum_{l \\in I} \\frac{1}{log(1 + n_l)}}{\\sqrt{\\mid J_1 \\mid \\cdot \\mid J_2 \\mid}}$$\n",
    "\n",
    "$n_l$表示喜欢物品l的用户数量，反映物品热门的程度，喜欢《哈利波特》的人数很多，$n_l$会很大，物品越热门，$n_l$越大，$1/log(1+n_l)$会越小，也就是物品的权重越小，这样一来，《哈利波特》对相似度的贡献就会很小, 而冷门物品的贡献会比较大。\n",
    "\n",
    "为了能在线上做到实时推荐，系统必须要事先做离线计算，建立两个索引：\n",
    "\n",
    "* 用户->物品的索引   用户ID：（物品ID，兴趣分数）的列表\n",
    "\n",
    "    * 记录每个用户最近点击、交互过的物品ID，以及记录用户对物品的兴趣分数。与ItemCF用到相同的索引。\n",
    "    * 给定任意用户ID，可以找到他近期感兴趣的物品列表以及兴趣分数。\n",
    "\n",
    "* 用户->用户的索引   用户ID：最相似的k个用户（ID，相似度）\n",
    "\n",
    "    * 与ItemCF不同，ItemCF用到的是物品到物品的索引，这里是用户到用户的索引；建索引的方法与ItemCF几乎相同，对于每个用户，索引他最相似的K个用户，比如k=10或者100，这个计算量会比较大。\n",
    "    * 有了用户到用户的索引之后，给定任意用户ID，可以快速找到他最相似的k个用户，而且知道用户相似度的分数。 \n",
    "\n",
    "线上做召回：\n",
    "\n",
    "有了索引之后，可以在线上给用户做实时推荐，比如现在有个用户刷App，系统要给用户做推荐：\n",
    "\n",
    "1. 系统知道这个用户的ID，通过“用户->用户”索引，找到top-k相似用户\n",
    "2. 对于每个top-k相似用户，通过“用户->物品”索引，找到用户近期感兴趣的物品列表(last-n)\n",
    "\n",
    "有了k个相似用户，每个用户有n个物品，那么一共取回了nk个物品。\n",
    "\n",
    "3. 对于召回的nk个相似物品，用公式预估用户对每个物品的兴趣分数，做计算的时候，需要用到列表中的用户之间的相似度数值和用户对物品的兴趣分数，把相似度和物品分数相乘，得到预估的兴趣分数，如果取回的物品有重复的，就做去重，把分数加起来，按照分数从高到低对物品做排序。\n",
    "4. 返回分数最高的100个物品，作为UserCF这个召回通道的输出。\n",
    "\n",
    "用这种方法做召回，在线上做计算的速度非常快。\n",
    "\n",
    "在工业界推荐系统中，ItemCF和UserCF都是主要的召回通道，为了在线上做非常快的召回，需要离线维护两个索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db753776",
   "metadata": {},
   "source": [
    "## 向量召回\n",
    "\n",
    "离散特征在推荐系统中非常常见，用户ID、物品ID，性别、国籍、英文单词都属于离散特征。\n",
    "\n",
    "离散特征处理分两步：\n",
    "\n",
    "1. 建立字典：把类别映射成序号\n",
    "2. 向量化： 把序号映射成向量\n",
    "    * One-hot编码：把序号映射成高纬稀疏向量\n",
    "        \n",
    "        比如性别，字典：男->1, 女->2\n",
    "        \n",
    "        编码后：未知->0->[0, 0]\n",
    "\n",
    "        男->1->[1, 0]\n",
    "\n",
    "        女->2->[0，1]\n",
    "\n",
    "        在实践中，类别数量太大时，通常不用one-hot编码。对于性别这样的离散特征，类别数量很少，可以直接用one-hot向量，但是对于单词、物品ID这样的离散特征，类别数量巨大，用one-hot向量过于稀疏，更常见的做法是embedding，把每个类别映射成一个低维稠密向量。\n",
    "\n",
    "    * Embedding：把序号映射成低维稠密向量\n",
    "\n",
    "        参数数量：向量维度*类别数量\n",
    "\n",
    "        编程实现：可以使用TensorFlow、Pytorch提供的Embedding层，在训练神经网络的时候，会自动做反向传播，学习embedding层的参数；embedding参数是一个矩阵，矩阵大小是向量维度x类别数量，embedding的输入是一个序号，输出是向量，参数矩阵的一行。一个神经网络绝大多数的参数都在embedding层，所以工业界深度学习系统都会对embedding层做很多优化，这是存储和计算效率的关键所在。\n",
    "\n",
    "        Embedding = 参数矩阵 x One-hot向量，从这个角度看，embedding就是矩阵和向量的乘法，与全连接层非常像。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90bbfd1",
   "metadata": {},
   "source": [
    "## 矩阵补充 （Matrix Completion）\n",
    "\n",
    "矩阵补充是最简单的一种向量召回方法，不过现在已经不太常用这种方法了，但是方便理解双塔模型\n",
    "\n",
    "基于embedding做推荐，模型的输入是一个用户ID和一个物品ID，模型的输出是一个实数，用户对物品兴趣的预估值。\n",
    "\n",
    "1. 用户ID -> Embedding Layer -> 向量a，是对用户的表征\n",
    "\n",
    "2. 物品ID -> Embedding Layer -> 向量b，是对物品的表征\n",
    "\n",
    "3. 内积<a, b>得到一个实数即为用户到物品兴趣的预估值,内积越大，说明用户对物品的兴趣越强\n",
    "\n",
    "两个Embedding层不共享参数，这个模型就是矩阵补充模型。\n",
    "\n",
    "训练的基本思想：\n",
    "\n",
    "* 用户emebdding参数矩阵记作A，每个用户对应矩阵的一行，第u号用户对应矩阵的第u行，记作$a_u$。\n",
    "\n",
    "* 物品embedding参数矩阵记作B, 每个物品对应矩阵的一行，第i号物品对应矩阵的第i行，记作$b_i$。\n",
    "\n",
    "* $<a_u, b_i>$是第u号用户对第i号物品兴趣的预估值。内积越大，说明用户u对物品i的兴趣越强。\n",
    "\n",
    "* 模型训练的目的是学习用户embedding矩阵A和物品embedding矩阵B，使得预估值拟合真实观测的兴趣分数。\n",
    "\n",
    "开始训练之前，首先要准备一个数据集：数据集是很多（用户ID，物品ID，兴趣分数）三元组的集合，记作 $\\Omega = \\{(u, i, y)\\}$, 是该用户对该物品真实的兴趣分数，在系统里有记录.\n",
    "\n",
    "数据集中的兴趣分数是系统里记录的，凡是曝光的，系统都会记录兴趣分数，比如：\n",
    "* 曝光但是没有点击，说明不感兴趣 -> 0分\n",
    "* 点击、点赞、收藏、转发 -> 各算1分，这些行为都说明用户对物品感兴趣\n",
    "* 兴趣分数最低是0分，最高是4分，训练的目的就是让模型的输出拟合兴趣分数。\n",
    "\n",
    "训练时求解优化问题：$min \\sum_{(u,i,j) \\in \\Omega} (y-<a_u, b_i>)^2$\n",
    "\n",
    "为什么这个模型叫做矩阵补充？\n",
    "\n",
    "例如有一个大矩阵，矩阵的每一行对应一个用户，每一列对应一个物品，矩阵中的每个元素表示一个用户对一个物品的真实兴趣分数，系统里物品很多，一个用户看过的物品只是系统里的极少数，在矩阵中，绿色位置表示曝光给用户的物品，灰色位置表示没有曝光给用户的物品，只要物品曝光给用户，我们就知道用户对物品是否感兴趣，曝光了没点击说明不感兴趣，分数是0，曝光之后用户可能会点击、点赞、收藏、转发，每个都算1分，加起来最多有4分，比如某个绿色位置表示第3号用户对第2号物品的兴趣分数是4，矩阵中只有少数位置是绿色，大多数位置都是灰色，就是没有曝光给用户的，我们并不知道用户对没曝光的物品是否感兴趣，我们拿绿色位置的数据训练模型，有了模型，就可以预估出所有灰色位置的分数，也就是把矩阵的元素给补全，这就是为什么模型叫做矩阵补充，把矩阵元素补全之后，就可以做推荐，给定一个用户，选出用户对应的行中分数较高的物品，推荐给该用户。\n",
    "\n",
    "矩阵补充并不是在工业界中能work的方法，在实践中效果不好，缺点：\n",
    "\n",
    "1. 仅利用ID embedding，没用利用物品属性、用户属性\n",
    "    \n",
    "    物品属性：类目、关键词、地理位置、作者信息\n",
    "\n",
    "    用户属性：性别、年龄、地理定位、感兴趣的类目\n",
    "\n",
    "    知道这些属性，召回可以做的更精准，双塔模型可以看作矩阵补充道升级版，双塔模型不仅使用物品ID、用户ID，还会结合各种物品属性和用户属性，双塔模型的实际表现非常好\n",
    "\n",
    "2. 负样本的选取方式不对\n",
    "\n",
    "    样本：用户—物品的二元组，记作(u, i)\n",
    "\n",
    "    训练召回模型需要正样本和负样本:\n",
    "    \n",
    "    正样本：物品给用户曝光之后，有点击、交互的行为；(正确的做法，工业界都这样做)\n",
    "    \n",
    "    负样本：曝光之后，没有点击、交互的物品；(错误的做法，学术界可能觉得没错，但实践中补work)\n",
    "\n",
    "3. 训练模型的方法不好\n",
    "\n",
    "    * 内积<a, b>作为兴趣分数的预估，这样没错，可以work，但是效果不如余弦相似度，工业界普遍使用余弦相似度而不是内积。 \n",
    "\n",
    "    * 矩阵补充用平方损失函数，也就是做回归，让预估的兴趣分数拟合真实的兴趣分数，这样做的效果不如交叉熵损失函数，也就是做分类，工业界通常做分类判定一个样本是正样本还是负样本。\n",
    "\n",
    "做完训练之后，要把模型存储在正确的地方，便于做召回：\n",
    "\n",
    "1. 训练得到矩阵A和B\n",
    "\n",
    "    * A的每一行对应一个用户\n",
    "    * B的每一行对应一个物品\n",
    "\n",
    "    线上做推荐时要用到A和B，当用户数和物品数都是好几亿时，矩阵会很大，为了快速读取和快速查找，需要特殊的存储方式\n",
    "\n",
    "2. 把矩阵A的每一行存储为key-value表，key是用户ID，value是A的一行，给定用户ID，在表中做查找，返回一个向量(用户的embedding)\n",
    "\n",
    "3. 矩阵B的存储和索引比较复杂，不能简单的用key-value存储\n",
    "\n",
    "\n",
    "线上服务：\n",
    "\n",
    "在训练好模型之后，并且把embedding向量做存储之后，可以把模型用作推荐系统中的召回通道。\n",
    "\n",
    "1. 某用户刷app时，app后台会开始做召回，把这个用户的ID作为key值，查询key-value表，得到该用户的embedding向量，记作a\n",
    "\n",
    "2. 我们要查找用户可能最感兴趣的k个物品作为召回结果，这叫做最近邻查找nearest neighbor search\n",
    "\n",
    "    把第i号物品的embedding向量记作$b_i$, 计算内积<a， b> 作为用户对第i号物品兴趣的预估，返回内积最大的k个物品，比如k=100，这些物品就是召回的结果。\n",
    "\n",
    "    这种最近邻查找有个严重的问题，如果逐一对比所有物品，时间复杂度会正比于物品数量，这种巨大的计算量是不可接受的，根本做不到线上的实时计算\n",
    "\n",
    "    如何加速最近邻查找，避免暴力枚举？\n",
    "\n",
    "    有很多算法加速最近邻查找，这些算法非常快，即使有几亿个物品，最多也只需要做几万次内积，比如实践中都用近似最近邻查找(Approximate Nearest Neighbor Search)，这些算法的结果未必是最优的，但是不会比最优结果差多少，快速最近邻查找的算法已经被集成到很多向量数据库系统中，比较有名的有Milvus、Faiss、HnswLib等\n",
    "\n",
    "    做最近邻查找，需要定义什么是最近邻，也就是衡量最近邻的标准：\n",
    "\n",
    "    * 欧式距离最小 （L2距离）\n",
    "    * 向量内积最大 （内积相似度），矩阵补充用的就是这个\n",
    "    * 向量夹角余弦最大 （cosine相似度），目前推荐系统最常用的，有些系统不支持余弦相似度，但很好解决，如果你把所有向量都做归一化，让他们的2范数全都等于1，那么内积就等于余弦相似度 \n",
    "\n",
    "    在做线上服务之前，先对数据预处理，把数据划分成很多区域，至于如何划分，取决于衡量最近邻的标准，如果是cosine相似度，划分的结果就是一个圆分为很多个扇形，如果是欧氏距离，划分的结果就是多边形，划分之后，每个区域用一个单位向量表示，向量的长度都是1，划分区域之后，建立索引，把每个区域的向量作为key，把区域中所有点的列表作为value，假如有1亿个点，那么划分成1w个区域，索引上一共有1w个key值，每个向量是一个区域点key值，给定一个向量，可以快速取回这个区域内所有的点。\n",
    "    \n",
    "    有了这样一个索引，就可以在线上快速做召回了，在线上给一个用户做推荐，这个用户的embedding向量记作a，首先把向量a跟索引中所有向量做对比，计算它们的相似度，如果物品数量是记忆，索引中的向量数量也只有几万而已，这一步的计算开销不大，计算相似度之后，发现索引中有一个向量与a最相似，通过索引找到这个区域内所有的点，每个点对应一个物品，接下来，计算a跟区域内所有点的相似度，几亿个物品被划分到了几万个区域，平均每个区域只有几万个点，所以这一步之需要计算几万次相似度，计算量也不大，比暴力枚举快1w倍。\n",
    "\n",
    "    矩阵补充是个学术界的模型，有许多缺点，导致效果不好，工业界不用矩阵补充模型，而是用更先进的双塔模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e803287",
   "metadata": {},
   "source": [
    "## 双塔模型\n",
    "\n",
    "双塔模型可以看作是矩阵补充的升级版\n",
    "\n",
    "用户特征，除了用户ID，还能从用户填写的资料和用户行为中获取很多特征，包括离散特征和连续特征，所有这些特征不能直接输入神经网络，而是要先做一些处理。\n",
    "\n",
    "用户特征处理：\n",
    "\n",
    "* 用户ID -> Embedding Layer\n",
    "\n",
    "* 用户离散特征（用户所在的城市、感兴趣的话题等等） -> Embedding Layers, 对于性别这种分类很少的离散特征，可以直接使用One-hot编码就行，不用做embedding。\n",
    "\n",
    "* 用户连续特征（比如年龄、活跃程度、消费金额） -> 不同类型的连续特征有不同的处理方法，最简单的处理方法是归一化（均值为0，方差为1），有些长尾分布的连续特征需要特殊处理，比如取log、分桶\n",
    "\n",
    "做完特征处理，得到很多特征向量，把这些向量都拼起来(concatenate),输入神经网络，可以是全连接网络也可以是深度交叉网络，神经网络输出一个向量，这个向量就是对用户的表征，做召回要用到这个向量。\n",
    "\n",
    "物品的特征也需要类似处理：\n",
    "\n",
    "* 物品ID ->  Embedding Layer\n",
    "\n",
    "* 物品离散特征 -> Embedding Layers\n",
    "\n",
    "* 物品连续特征 -> 归一化、取对数、分桶处理\n",
    "\n",
    "把得到的特征输入神经网络，神经网络输出的向量就是物品的表征，用于召回\n",
    "\n",
    "这样的模型就叫双塔模型，左边的塔提取用户的特征，右边的塔提取物品的特征，与矩阵补充不同，就在于使用了除了ID之外的多种特征，两个塔输出的向量a和b的内积<a, b> 即为模型的输出，预估用户对物品的兴趣，现在更常用余弦相似度$cos(a, b) = \\frac{<a, b>}{||a||_2 \\cdot ||b||_2}$,其实就相当于先对两个向量做归一化，然后求内积，大小介于（-1，1）。\n",
    "\n",
    "双塔模型的训练，有三种方式：\n",
    "\n",
    "* Pointwise: 独立看待每个正样本、负样本，最简单的训练方式，把召回看作简单的二元分类\n",
    " \n",
    "    每次用一个用户、一个物品，物品可以是正样本也可以是负样本\n",
    "\n",
    "    * 把召回看作是简单的二元分类任务\n",
    "    * 正样本意思是历史记录显示用户对物品感兴趣，对于正样本，鼓励cos(a, b)接近于+1\n",
    "    * 负样本意思是用户对物品不感兴趣，对于负样本，鼓励cos(a, b)接近于-1，这就是很典型的二元分类任务。\n",
    "    * 控制正负样本的数量为1:2, 1:3, 大佬也不知道为什么，但互联网大厂的人都这么做，算是业内的经验\n",
    "\n",
    "* Pairwise: 每次取一个正样本、一个负样本，组成一个二元组，损失函数用Triplet hinge loss 或者Triplet logistic loss, 参考Facebook这篇论文：Embedding-based Retrieval in Facebook Search.\n",
    "\n",
    "    做训练时，每一组的输入是一个三元组，包括一个用户和两个物品，(物品正样本， 用户， 物品负样本)， 三者的特征各自做变换，然后输入神经网络，两个物品塔是相同的，里面的Embedding层和全连接层都用一样的参数，输出三个向量(b+, a, b-), 分别计算用户对两个物品的兴趣，cos(a, b+)值越大越好，最好接近+1，cos(a, b-)值最好接近-1；\n",
    "\n",
    "    做pairwise的基本想法，是让用户对正样本的兴趣尽量大，对负样本的兴趣尽量小，即鼓励cos(a, b+) 大于 cos(a, b-), 而且两者之差越大越好。\n",
    "    \n",
    "    推导损失函数：我们希望看到用户对正样本的兴趣很大，而对负样本的兴趣很小，最好前者比后者大m这么多，这个m是个超参数，需要调，比如设置为1，如果前者比后者大了m，那么就没有损失，否则，如果用户对正样本的兴趣不够大，没有比负样本的兴趣大m这么多，就会有损失，损失为$cos(a, b^-) + m - cos(a, b^+)$，这样久推导出了下面的Triplet hinge loss。\n",
    "\n",
    "    Triplet hinge loss:\n",
    "    $$L(a, b^+, b^-) = max{0, cos(a, b^-)+m-cos(a, b^+)}$$\n",
    "\n",
    "    训练时，向量a, b+, b-分别为对用户、正样本、负样本的表征，我们希望损失函数越小越好，训练的过程就是对损失函数求最小化，用梯度更新双塔神经网络的参数。\n",
    "\n",
    "    Triplet logistic loss:\n",
    "    $$L(a, b^+, b^-) = log(1 + exp[\\sigma \\cdot (cos(a, b^-) - cos(a, b^+))])$$\n",
    "\n",
    "    $\\sigma$是个大于0的超参数，控制损失函数的形状，需要手动设置。这个损失函数与Triplet hinge loss起到同样的作用。\n",
    "\n",
    "* Listwise: 每次取一个正样本、多个负样本组成一个list，训练方式类似于多元分类，参考YouTube这篇论文：Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations. \n",
    "\n",
    "    做listwise训练时，每次取1个正样本和很多负样本\n",
    "        * 1条数据包含：\n",
    "            * 一个用户，特征向量记作a\n",
    "            * 取一个正样本，意思是历史记录显示用户喜欢这个物品，把这个物品的特征向量记作b+\n",
    "            * 取n个负样本，把它们的特征向量记作$b_1^-, b_2^-, ... , b_n^-$\n",
    "\n",
    "        * 做训练时要鼓励cos(a, b+)尽量大\n",
    "\n",
    "        * 鼓励$cos(a, b_1^-), ..., cos(a, b_n^-)$尽量小\n",
    "\n",
    "    把n+1个余弦相似度的分数输入softmax激活函数，输出n+1个介于（0，1）之间的分数$s^+, s_1^-,..., s_n^-$，对应正样本的1个分数，我们希望越大越好，最好接近1，对应负样本的n个分数，我们希望越小越好，最好接近0；\n",
    "\n",
    "    正样本的标签$y^+=1$，意思是鼓励$s^+$接近1，负样本的标签是$y_1^-=...=y_n^-$把它们都设置为0,意思是鼓励$s_1^-,..., s_n^-$都接近0，我们用y和s的交叉熵作为损失函数$CrossEntropyLoss(y, s) = -log s+$, 训练时最小化交叉熵，意思是鼓励softmax输出s接近标签y，最小化交叉熵也就是最大化s+，即最大化正样本的余弦相似度，最小化负样本的余弦相似度。\n",
    "\n",
    "正负样本的选择：\n",
    "\n",
    "    训练的时候要用到正样本和负样本，选对正负样本，作用大于改进模型结构，该如何选择正负样本呢？\n",
    "\n",
    "* 正样本：如果物品给用户曝光之后，用户点击过一个物品，就说明用户对这个物品感兴趣。正样本就是曝光而且有点击的用户-物品二元组。\n",
    "\n",
    "    问题：少部分物品占据大部分点击，正样本是有点击的物品，导致正样本大多是热门物品。把过多的热门物品作为正样本，会对冷门物品不公平，这样会让热门物品更热，冷门更冷。\n",
    "\n",
    "    解决方案：对冷门物品过采样，或降采样热门物品。\n",
    "        * 过采样 up-sampling, 一个样本出现多次\n",
    "        * 降采样 down-sampling, 一些样本被抛弃。比如，以一定概率抛弃热门物品，抛弃的概率与样本的点击次数正相关。\n",
    "\n",
    "* 负样本：用户不感兴趣的物品，也就是推荐链路上召回、粗排、精排、重排每一步被淘汰的物品。召回模块中从几亿个物品中选出几千个，被召回的物品只是极少数，这些没被召回的几亿个物品可以看作是负样本；粗排和精排从几千个物品中选出几百个，也就是说几千个物品会被这一步淘汰；最终有几十个物品被曝光给用户，但不是每个被曝光的都会被点击，曝光了但是没有被用户点击的也可以视作是负样本。负样本的选择没有那么显然，在实践中，负样本的选择是比较讲究的。\n",
    "\n",
    "    有几种看起来比较合理的负样本：\n",
    "\n",
    "    1. 没有被召回的？\n",
    "        \n",
    "        对的。\n",
    "        \n",
    "        未被召回的物品，大概率是用户不感兴趣的。\n",
    "\n",
    "        方法一，简单负样本：全体物品\n",
    "        \n",
    "        几亿个物品里，只有几千个被召回，未被召回的物品$\\approx$全体物品，所以直接在全体物品中做随机抽样就可以，抽到的物品作为负样本。\n",
    "\n",
    "        问题怎么做抽样？均匀抽样 or 非均匀抽样？\n",
    "\n",
    "        均匀抽样的坏处是对冷门物品不公平，因为少部分物品占据了大部分点击，正样本大多是热门物品。而从全体笔记中做均匀抽样产生负样本，那么负样本大多是冷门物品，总拿热门物品做正样本，冷门物品做负样本，对冷门物品会不公平。这样会让热门物品更热，冷门物品更冷。所以负样本抽样要随机非均匀。\n",
    "\n",
    "        非均匀随机抽样可以打压热门物品。负样本抽样概率与热门程度（点击次数）正相关，热门物品成为负样本的概率大，物品的热门程度可以用它的点击次数来衡量，可以这样做抽样：抽样概率正比于$(点击次数)^{0.75}$， 0.75是个经验值。\n",
    "\n",
    "        方法二，简单负样本：Batch内负采样\n",
    "\n",
    "        设一个batch内有n个正样本，一个用户和n-1个物品可以组成负样本，这个batch内一共有n(n-1)个负样本，都属于简单负样本。\n",
    "\n",
    "        问题：batch内的正样本都是通过点击行为选取的，一个物品出现在batch内的概率正比于它的点击次数，也就是它的热门程度，前面讨论了物品称为简单负样本的概率应该是正比于$(点击次数)^{0.75}$, 但在这里做batch内负采样，物品成为负样本的概率是正比于点击次数，也就是说热门物品成为负样本的概率过大，一个物品成为负样本的概率越大，模型对这个物品打压就会越狠，对负样本应该打压，但这里对热门物品打压的太狠了，会造成偏差，YouTube那篇论文讲了如何修正偏差。\n",
    "\n",
    "        修正偏差做法：\n",
    "\n",
    "        物品i被抽样到的概率： $p_i \\propto 点击次数$，反映出物品的热门程度，双塔模型通常用$cos(a, b_i)$预估用户对物品i的兴趣分数，训练时要鼓励正样本的余弦相似度尽量大，鼓励负样本的余弦相似度尽量小，根据Youtube论文的建议，训练双塔模型的时候，把$cos(a, b_i)$调整为$cos(a, b_i) - logp_i$, 这样可以纠偏，避免过分打压热门物品，训练结束后，在线上做召回时，还是用原来的余弦相似度$cos(a, b_i)$，不用减$logp_i$。\n",
    "\n",
    "\n",
    "\n",
    "    2. 召回但是被粗排、精排淘汰的？\n",
    "        对的。\n",
    " \n",
    "        被粗排淘汰的物品 （比较困难）\n",
    "\n",
    "        被召回说明这些物品与用户兴趣多少有些关系，被粗排淘汰说明用户对物品的兴趣不够强，所以分为了负样本。对正负样本做二元分类，这些负样本容易被分错，容易被错误的判断为正样本。\n",
    "\n",
    "        通过了粗排，但精排分数靠后的物品 （非常困难）\n",
    "\n",
    "        能够通过粗排进入精排说明物品已经比较符合用户兴趣了，但未必是用户最感兴趣的，所以在精排中排名靠后的物品可以被视为负样本。\n",
    "\n",
    "        训练双塔模型其实是个二元分类任务，让模型去分正负样本。把全体物品作为简单负样本，分类准确率会很高，因为它们明显会与用户兴趣不符。被粗排淘汰的物品作为负样本，但它们与用户兴趣有些相关，所以比较困难，分类准确率会稍微低一些。精排分数靠后的物品也可以作为负样本，这些物品与正样本有些相似，所以很容易被判定为正样本，对它们做分类非常困难。\n",
    "\n",
    "        工业界比较常用的做法是，把简单负样本和困难负样本混合起来作为训练数据，比如50%是简单负样本，就是从全体物品中随机非均匀抽样出来的，另外50%是困难负样本，也就是从粗排、精排淘汰的物品中随机抽样出来的。\n",
    "\n",
    "    3. 曝光但是用户没有点击的？\n",
    "        错误。\n",
    "\n",
    "        训练双塔模型，用一些这样负样本，效果肯定会变差，工业界的已经踩过这个坑。这些负样本不是给召回模型用的，而是给排序模型用的，训练排序模型时确实需要这种曝光但是没有被点击的物品作为负样本。\n",
    "\n",
    "        选择负样本的原理：\n",
    "\n",
    "        召回的目的是快速找到用户可能感兴趣的物品，凡是用户可能感兴趣的全都取回来，然后再交给后面的排序模型逐一做甄别。召回模型的任务是区分用户不感兴趣的物品和可能感兴趣的物品，而不是区分比较感兴趣的物品和非常感兴趣的物品，这就是选择负样本的基本思路。因此可以把全体物品当作负样本，把它们叫做简单负样本，这些用物品绝大多数都是用户根本不感兴趣的，双塔模型很容易去分这些负样本。被召回但是被粗排、精排淘汰的叫做困难负样本，被召回说明它们跟用户的兴趣有一定的相关性，被排序模型过滤掉说明用户对这些物品的兴趣不够强，它们可以作为负样本，这样的负样本和正样本有点像，做分类的时候难以区分，所以算是困难负样本。有曝光但是没有点击的物品，看起来可以当作负样本，但其实不能，只要用了这种负样本，双塔模型的效果肯定会变差，为什么呢？一个物品能够通过精排模型的甄别，最终曝光给用户，说明物品已经非常匹配用户的兴趣点了，每次给用户展示几十个物品，用户不可能每个物品都点击，没有点击不代表不感兴趣，可能只是精力有限不想刷了，曝光没有点击的物品已经算是非常匹配了，甚至可以拿来作为召回的正样本了。召回的目的是区分不感兴趣的和比较感兴趣的。而排序才是区分比较感兴趣的和非常感兴趣的。这类负样本只适用于排序模型，但不适用于召回模型，这是工业界的共识，是经过反复做实验得出的结论。\n",
    "\n",
    "\n",
    "在粗排、精排模型中，经常是把用户特征向量和物品特征向量先concatenate一起后，输入神经网络，这是前期融合模型，适用于排序，前期融合模型不适用于召回，假如把这种模型用于召回，就必须把所有物品特征挨个输入模型，预估用户对所有物品的兴趣，假设一共有1亿个物品，每给用户做一次召回，就要把这个模型跑1亿次，这种计算量显然不可行，如果用这种模型，就没办法再用最近邻查找来加速计算，这种模型通常用于排序，从几千个候选物品中选出几百个，计算量不会太大，看到前期融合模型就要明白这个排序模型，不是召回模型。双塔模型属于后期融合，两个塔只有在最终输出相似度时才融合起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081b6a1",
   "metadata": {},
   "source": [
    "### 双塔模型： 线上召回和更新\n",
    "\n",
    "在训练好双塔模型之后，就可以把模型部署到线上做召回。在训练好模型之后，在开始线上服务之前，先要做离线存储，用神经网络计算每个物品的特征向量b，把几亿个物品的 <特征向量b，物品ID>这样的二元组保存到faiss向量数据库中，向量数据库会建立索引，建索引就是把向量空间划分为很多区域，每个区域用一个向量表示，这样可以加速最近邻查找。用户塔则不需要事先计算和存储用户特征向量，而是当用户发起推荐请求的时候，给定用户ID和用户画像，调用用户塔神经网络在线上现算一个特征向量a，然后把向量a作为query，去向量数据库中做检索，查找最近邻，也就是跟向量a相似度最高的k个物品向量，每个物品向量对应一篇笔记，作为这条召回通道的结果返回，然后与ItemCF，Swing，UserCF的召回通道的结果融合，然后经过排序，最终展示给用户。\n",
    "\n",
    "为什么存储物品向量，而线上现算用户向量呢？\n",
    "\n",
    "1. 线上算物品向量的代价过大：每做一次召回，只用到一个用户向量a，而用到几亿个物品向量b，拿神经网络现算一个用户向量，计算量不大，算的起，但几亿个物品向量显然是算不起的，所以不得不离线算好物品向量。\n",
    "2. 用户兴趣是动态变化的，所以应该在线上实时计算用户向量，而不是离线算好存起来，事先存储用户向量，效果不好，但事先存储物品向量可以，物品特征相对比较稳定，短期内不会发生变化。\n",
    "\n",
    "模型更新\n",
    "\n",
    "全量更新：比如今天凌晨，用昨天的全天数据训练模型。注意是在昨天模型参数的基础上做训练，而不是随机初始化。把昨天一天的数据打包成tfrecord文件，在昨天模型参数的基础上做训练，把昨天的数据过一遍，每条数据只用一次，也就是训练只做1 epoch。训练完成之后，发布新的用户塔神经网络和物品向量，用户的作用在线上实时计算用户特征向量，作为召回query，物品向量存入向量数据库，向量数据库会重新建索引，然后在线上做最近邻查找。全量更新对数据流和系统的要求不高，不需要实时的数据流，对生成训练数据的速度没有要求，延迟1-2个小时没关系，只需要把每天的数据落表，在凌晨做个批处理，把数据打包成tfrecord格式的文件就可以。全量更新对系统的要求也很低，每天做一次全量更新，只需要把用户塔神经网络和物品向量发布一次就够了。\n",
    "\n",
    "增量更新：做online learning更新模型参数。每隔几十分钟就把新的模型参数发布出去。\n",
    "\n",
    "为什么要做增量更新？\n",
    "\n",
    "因为用户的兴趣会随时发生变化，想要模型在用户行为发生几小时之内就做出反应，模型需要做到小时级别的增量更新，天级别的全量更新是不行的。增量更新对数据流的要求很高，需要实时收集线上的数据，并且对数据做流式处理，实时生成训练模型用的tfrecord文件，然后对模型做online learning，做梯度下降更新ID embedding的参数，也就是从早到晚，训练数据文件不断生成，不断做梯度下降更新模型的embedding层，注意online learning不更新神经网络其他部分的参数，全连接层的参数都是锁住的，不做增量更新，只更新embedding层的参数。只有做全量更新的时候，才会更新全连接层，主要出于工程实现的考量。对模型更新之后，再把算出的用户ID embedding发布出去，是一个hash表的形式，给定用户ID，可以查出ID embedding向量。发布ID embedding的目的，是为了线上计算用户特征向量。最新的用户ID embedding可以捕捉到用户最新的兴趣点，对推荐很有帮助。发布用户ID embedding这个过程会有延迟，会有小时级的延迟，通过对系统做优化，延迟可以降低到几十分钟甚至更短。\n",
    "\n",
    "注意，今天凌晨做全量更新时是在昨天凌晨的全量更新的模型的参数基础上的，而不是在昨天增量更新的模型基础上，全量更新完成后，之前的增量更新模型就可以全部扔掉了，然后在新的模型上做分钟级别等增量更新，从今天凌晨到明天凌晨，不停做online-learning，每隔几十分钟发布一次模型。工程实践上发现只做增量更新的效果不好，最好还是既要做全量还要做增量。\n",
    "\n",
    "只做增量为什么效果不好？\n",
    "\n",
    "如果只看小时级别的数据，是有偏的，它的统计值和全天的数据差别很大，因为在不同的时间段，用户的行为是不一样的，比如中午和傍晚会明显不一致，而分钟级的数据偏差会更大。我们在做全量数据时，会随机shuffle一天的数据，会消除偏差。而增量更新的数据是从早到晚的顺序。同样用一天的数据，这两种排列数据的方式，效果会有差别。随机打乱优于按顺序排列数据，所以全量更新优于增量更新。实际系统都会结合全量更新和增量更新，全量训练的模型更好，而增量训练可以实时捕捉用户兴趣的变化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adb577",
   "metadata": {},
   "source": [
    "## 其他几种召回通道\n",
    "\n",
    "这几个召回通道很有用，但重要性不高。\n",
    "\n",
    "### 地理位置召回\n",
    "#### GeoHash召回\n",
    "\n",
    "之所以用这个召回通道，原理是因为用户可能对附近的人或发生的事感兴趣，推荐系统应该推一些用户附近的内容。系统维护一个地理位置GeoHash索引，对经纬度编码为二进制hash码，方便检索。每个GeoHash表示地图上一个长方形区域。\n",
    "\n",
    "索引：GeoHash -> 优质笔记列表（按时间倒排），以GeoHash为索引，记录地图上一个长方形区域内的优质笔记，笔记列表按时间顺序倒排，最新的笔记排在最前面。做召回时，给定用户的GeoHash，会取回这个区域内比较新的优质笔记，这条召回通道没有个性化，纯粹只看地理位置，完全不考虑用户兴趣。因为没有个性化，所以才用优质笔记，笔记本身质量好，即使没有个性化，用户也可能喜欢看。反过来，既没有个性化，也不是优质笔记，那么召回的笔记大概率通不过粗排和精排。GeoHash召回的笔记中有哪些符合用户的兴趣，留待排序决定。\n",
    "\n",
    "#### 同城召回\n",
    "\n",
    "原理与GeoHash召回一样，用户可能对同城发生的事感兴趣，唯一的区别是用城市作为召回索引。\n",
    "\n",
    "索引：城市 -> 优质笔记列表 （按时间倒排）。做召回时，根据用户所在的城市和曾经生活过的城市做召回，这条召回通道也没有个性化。\n",
    "\n",
    "### 作者召回\n",
    "#### 关注的作者召回\n",
    "\n",
    "原理是如果用户对一个作者感兴趣，系统会给用户推这个作者发布的新笔记。带社交属性的推荐系统，都会有关注作者这样一个召回通道。\n",
    "\n",
    "系统维护两个索引：\n",
    "1. 用户 -> 关注的作者\n",
    "2. 作者 -> 发布的笔记，笔记的列表按照时间顺序倒排\n",
    "\n",
    "召回：给定用户ID，找到关注的所有作者，再取回每个作者最新发布的笔记，这样就得到了一批笔记。\n",
    "\n",
    "#### 有交互的作者召回\n",
    "\n",
    "原理： 如果用户对某笔记点赞、收藏、转发，说明用户对该作者笔记感兴趣，那么用户可能对该作者对其他笔记感兴趣。所以即使用户不关注作者，系统也应该继续给用户推荐他的视频。\n",
    "\n",
    "系统维护的索引：\n",
    "\n",
    "索引：用户 -> 有交互的作者列表，作者列表需要定期更新，最简单的策略是保留最近交互的作者，删除一段时间没有交互的作者。\n",
    "\n",
    "召回：用户 -> 有交互的作者 -> 最新的笔记。在线上做召回时，给定用户ID，用索引找到有交互的作者，然后召回每个作者最新的笔记，这样就得到很多篇笔记\n",
    "\n",
    "#### 相似的作者召回\n",
    "\n",
    "原理：如果用户喜欢某个作者，那么用户可能会喜欢相似的作者\n",
    "\n",
    "系统需要维护一个从作者到相似作者的索引：\n",
    "\n",
    "索引：作者 -> 相似作者，作者相似性的计算类似ItemCF，如果两个作者的粉丝有很大的重合，那么就判定两个作者相似。\n",
    "\n",
    "召回：线上做召回时，给定用户ID，找到他感兴趣的作者，包括用户关注的作者，用户有交互的作者，利用索引，找到每个作者相似的一批作者，最后取回每个作者最新的一篇笔记，这样就召回了很多篇笔记。假设用户感兴趣的作者有n个，每个作者有k个相似作者，一共有nk个相似作者，一共召回了nk篇笔记。\n",
    "\n",
    "### 缓存召回\n",
    "\n",
    "原理：复用推荐系统之前n次精排的结果\n",
    "\n",
    "背景：\n",
    "\n",
    "* 精排输出几百篇笔记，送入重排；\n",
    "\n",
    "* 重排做多样性抽样，比如用DPP从几百篇笔记中选出几十篇曝光给用户；\n",
    "\n",
    "* 精排的结果一大半没有被曝光，被浪费掉，这很可惜，好不容易走完召回、粗排、精排流程，只是碰巧随机抽样没有抽到，所以没有被曝光，应该想办法把这些笔记重新利用起来。\n",
    " \n",
    "按照精排的分数做排序，把精排前50，但是没有曝光的，不要浪费掉，缓存起来，作为一条召回通道。下次用户刷app时，把缓存的笔记取出来，作为一路召回的结果。精排排到前50的都是用户非常感兴趣的，值得再次尝试。\n",
    "\n",
    "缓存召回的问题，缓存大小是固定的，比如最多存100篇笔记，每次就召回这100篇笔记，由于缓存大小固定，需要退场机制，确保缓存里最多有100篇笔记。有很多条规则作为退场机制。\n",
    "\n",
    "1. 比如一旦笔记成功曝光给用户，就从缓存退场\n",
    "\n",
    "2. 如果超出缓存大小，就移除掉最先进入缓存的笔记\n",
    "\n",
    "3. 每篇笔记最多被召回10次，达到10次就退场\n",
    "\n",
    "4. 每天笔记最多保存3天，时间达到3天就退场\n",
    "\n",
    "这些都是最简单粗暴的规则，在这些规则基础上，还可以细化规则，假如想要扶持曝光比较低的笔记，那么可以根据笔记的曝光次数来设置规则，让低曝光的笔记在缓存里存更长的时间。\n",
    "\n",
    "这几条召回通道都是工业界实际在用的，但重要性比不上ItemCF，Swing，双塔召回通道。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32aaa5",
   "metadata": {},
   "source": [
    "# 排序\n",
    "\n",
    "粗排和精排的原理相同，只是粗排模型小、特征少、效果差一些，粗排的目的是做快速的筛选，如果不用粗排，直接把很大的精排模型用在几千篇候选笔记上，计算代价承受不住。\n",
    "\n",
    "排序的主要依据是用户对物品的兴趣，兴趣可以反映在用户对物品的交互上，对于每个物品，系统会记录如下统计量：\n",
    "\n",
    "* 曝光次数 (number of impressions), 一个物品被展示给多少个用户，展示之后才会有点击等行为。\n",
    "\n",
    "* 点击次数 (number of clicks), 一个物品被多少个用户点开。\n",
    "\n",
    "* 点赞次数 (number of likes)\n",
    "\n",
    "* 收藏次数 (number of collects)\n",
    "\n",
    "* 转发次数 (number of shares)\n",
    "\n",
    "可以用点击率这类的消费指标衡量笔记的受欢迎程度。\n",
    "\n",
    "点击率 = 点击次数 ／ 曝光次数， 差不多10%-20%，用户点开之后才会发生点赞、收藏、转发等行为。\n",
    "\n",
    "点赞率 = 点赞次数 ／ 点击次数\n",
    "\n",
    "收藏率 = 收藏次数 ／ 点击次数\n",
    "\n",
    "转发率 = 转发次数 ／ 点击次数， 转发是很少见的行为，远少于点赞和收藏，但是转发很重要，可以从其他平台吸引到外部的流量\n",
    "\n",
    "推荐系统召回几千篇笔记，然后做排序，选出几十篇给用户，那么排序的依据是什么呢？在把笔记展示给用户之前，事先预估用户对笔记的兴趣：\n",
    "\n",
    "* 用排序模型预估点击率、点赞率、收藏率、转发率等多种分数\n",
    "\n",
    "* 预估之后，要对这些分数做融合，最简单的融合公式就是加权和，点击率权重为1，点赞、收藏、转发权重为2，权重是通过AB测试调出来的\n",
    "\n",
    "* 最后按照融合后的分数给笔记做排序和截断，保留分数最高的笔记，淘汰分数低的笔记\n",
    "\n",
    "## 多目标模型\n",
    "\n",
    "现在工业界基本都用这种模型，当然会在这个基础上做很多改进。\n",
    "\n",
    "排序模型的输入是各种各样的特征，把能用到的特征都用到了\n",
    "\n",
    "* 用户特征，主要是用户ID和用户画像\n",
    "\n",
    "* 物品特征，包括物品ID，物品画像，作者信息\n",
    "\n",
    "* 统计特征，包括用户统计特征和物品统计特征，比如用户在过去30天内一共曝光了多少篇笔记，点击了多少篇笔记，点赞了多少篇笔记；比如候选物品在过去30天中获得了多少曝光机会，获得多少次点击、点赞\n",
    "\n",
    "* 场景特征，是随着用户请求传过来的，包含当前的时间，用户所在的地点, 这些信息对推荐很有用，比方说用户和候选物品在同一个城市，那么用户可能会有更高的兴趣；比如当前是周末或者节假日，也会影响用户的兴趣\n",
    "\n",
    "把这些特征做concatenation输入神经网络，可以是简单的全连接网络，可以是wide&deep，也可以是更复杂的网络，神经网络会输出一个向量，这个向量再输入4个神经网络，每个神经网络有2-3个全连接层+最后sigmoid激活函数，4个神经网络分别输出点击率、点赞率、收藏率、转发率等预估值$p_1, p_2, p_3, p_4$，4个预估值都是实数，介于（0，1），推荐系统排序就主要靠这4个预估值，它们反映出用户对物品的兴趣。\n",
    "\n",
    "训练时让4个预估值去拟合真实的目标，把真实的目标记作$y_1, y_2, y_3, y_4$，分别对应点击、点赞、收藏、转发的行为，y值要么是0要么是1，比如（1，0，0，1），用户有点击、转发，没有点赞、收藏，这些是用户真实的行为，被系统记录下来，我们要用这样的数据来训练模型。训练是要鼓励模型的预测接近目标，其实这就是二元分类，比如判定用户是否会点击物品。有点击、点赞、收藏、转发这4个任务，每个任务都是一个二元分类，既然是二元分类，就用交叉熵损失函数。对于点击这个任务，损失函数为$CrossEntropy(y_1, p_1) = -(y_1 * ln p_1 + (1-y_1)*ln(1-p_1))$。把4个损失函数的加权和作为总的损失函数:$\\sum_{i=1}^{4} \\alpha_i * CrossEntropy(y_i, p_i)$。权重$\\alpha$是根据经验设置的。在收集的历史数据上训练神经网络的参数，最小化损失函数，损失函数越小，说明模型的预测越接近真实的目标。做训练的时候，把损失函数关于神经网络的参数求梯度，做梯度下降更新神经网络的参数。\n",
    "\n",
    "实际的训练中会有许多困难：\n",
    "* 做训练时存在类别不平衡的问题，正样本少，负样本多\n",
    "    * 比如每曝光100篇笔记，约有10次点击，90次无点击。有点击的是正样本，没点击的是负样本；\n",
    "    * 比如用户点开100篇笔记后，每100次点击，约有10次转发或者收藏，90次无转发或收藏，有转发／收藏点是正样本，无转发／收藏的是负样本。\n",
    "\n",
    "    太多的负样本用处不大，白白浪费计算资源\n",
    "\n",
    "    解决方案：负样本降采样 (down-sampling)\n",
    "    * 负样本过多，不用全部的负样本，只保留一小部分负样本\n",
    "    * 让正负样本数量平衡， 节约计算\n",
    "\n",
    "给定用户特征和物品特征，用神经网络预估出点击率、点赞率等之后，要对这些预估分数做校准，做校准之后才能把预估值做排序。\n",
    "\n",
    "为什么需要校准？\n",
    "\n",
    "* 设正样本和负样本数量分别为n+, n-，负样本数量通常远大于正样本；\n",
    "\n",
    "* 在做训练时会对负样本降采样，抛弃一部分负样本，让正负样本的差距不太悬殊\n",
    "\n",
    "* 把采样率记为$\\alpha$，使用$\\alpha \\cdot n_{\\_}$个负样本，$\\alpha \\in (0, 1)$\n",
    "\n",
    "* 由于负样本变少，模型预估的点击率会大于真实点击率，$\\alpha$越小，负样本越少，模型对点击率的高估就会越严重\n",
    "\n",
    "预估值校准：参考文献Practical lessions from predicting clicks on ads at facebook.\n",
    "\n",
    "推导公式：\n",
    "\n",
    "* 真实点击率 $p_{true} = \\frac{n_+}{n_+ + n_{\\_}}$ (期望)\n",
    "\n",
    "* 预估点击率 $p_{pred} = \\frac{n_+}{n_+ + \\alpha \\cdot n_{\\_}}$ (期望)\n",
    "\n",
    "* 由上面两个公式，消掉n+, n-，可得校准公式：\n",
    "\n",
    "$$p_{true} = \\frac{\\alpha \\cdot p_{pred}}{(1-p_{pred}) + \\alpha \\cdot p_{pred}}$$\n",
    "\n",
    "$p_{true}$校准之后的点击率，在线上做排序时，首先让模型预估点击率$p_{pred}$，然后套入公式做校准，把校准后的点击率作为排序的依据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be30ba7",
   "metadata": {},
   "source": [
    "### Multi-gate Mixture-of-Experts (MMOE)\n",
    "\n",
    "模型的输入是一个向量，包含用户特征、物品特征、统计特征、场景特征，把向量输入3个神经网络，3个神经网络结构相同，都是由很多全连接层组成，但这3个神经网络不共享参数，3个神经网络各输出一个向量$x_1, x_2, x_3$, 3个神经网络被叫做专家，就是experts，实践中通常会试4个或8个神经网络，数量是个超参数需要调。\n",
    "\n",
    "把输入向量输入左边一个神经网络，这个神经网络最后加一个softmax激活函数，输出一个3维向量$(p_1, p_2, p_3)$，向量和为1，分别对应3个专家神经网络，之后会用这3个元素作为权重，对向量$x_1, x_2, x_3$做加权平均。\n",
    "\n",
    "同样把输入向量输入右边一个神经网络，最后也是加一个softmax激活函数，输出一个3维向量$(q_1, q_2, q_3)$, 也是之后做加权平均时的权重。\n",
    "\n",
    "用左边权重p对向量x做加权平均，得到$p_1x_1 + p_2x_2 + p_3x_3$，然后输入一个神经网络，有1个或多个全连接层，神经网络的输出取决于具体的任务，比如输出对点击率低预估，介于（0，1）\n",
    "\n",
    "用右边权重q对向量x做加权平均，得到$q_1 x_1 + q_2 x_2 + q_3 x_3$，然后输入另一个神经网络，输出另一个指标的预估，比如点赞率，也是介于（0，1）\n",
    "\n",
    "这里多目标模型是假设有点击率、点赞率两个指标，所以用了$p, q$两组权重，假如有10个指标，则需要10组权重。\n",
    "\n",
    "实践中，大家都发现MMOE有个问题，softmax会发生极化（polarization）。\n",
    "\n",
    "极化现象：softmax输出向量中，一个值接近于1，其他值接近于0。比如左边p的权重约等于(0, 0, 1), 也就是说点击率任务只使用了第3个专家神经网络，而没有使用其他两个专家神经网络。这样就没有用mixture of experts，没有让3个专家神经网络的输出融合，而是简单使用了1个专家。右边的权重接近(0, 1, 0)，则点赞率只使用了第2个专家神经网络，也没有对3个专家做融合。而且综合看第1号专家网络没有被用到，相当于死掉了，MMOE则相当于一个简单的多目标模型，不会对专家做融合，失去了MMOE的优势。\n",
    "\n",
    "解决方案：\n",
    "\n",
    "* 如果有n个专家神经网络，则每个softmax激活函数的输入和输出都是n维向量，我们不希望看到其中一个元素接近1，其余元素接近0；\n",
    "\n",
    "* 解决极化现象的一种方法是Dropout， 在训练时，对softmax的输出使用dropout，softmax输出的n个值被mask的概率都是10%，训练时每个专家被丢弃的概率都是10%，这样强迫每个任务根据部分专家做预测，用dropout不太可能会发生极化，否则预测的结果会特别差。假如发生了极化，softmax输出的某个元素接近1，万一这个元素被mask，预测的结果肯定很差，为了让预测精准，神经网络会尽量避免发生极化，避免softmax输出的某个元素接近1。用了dropout基本上能避免发生极化。\n",
    "\n",
    "Google提出MMOE的文献：Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-experts.\n",
    "\n",
    "Youtube解决极化的文献：Recommending what video to watch next: A multitask ranking system.\n",
    "\n",
    "经过实践，MMOE有的有提升，有的没有提升。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa4ecd",
   "metadata": {},
   "source": [
    "## 预估分数融合\n",
    "\n",
    "多目标模型输出对点击率、点赞率等指标的预估，怎样融合多个预估分数？\n",
    "\n",
    "1. 最简单的预估值融合方法就是求加权和：\n",
    "\n",
    "    $$p_{click} + w_1 \\cdot p_{like} + w_2 \\cdot p_{collect} + ...$$\n",
    "\n",
    "    $p_{click}$点击率的权重是1，其他指标的权重各不同。\n",
    "\n",
    "2. 点击率乘以其他项的加权和：\n",
    "\n",
    "    $$p_{click} \\cdot (1 + w_1 \\cdot p_{like} + w_2 \\cdot p_{collect} + ...)$$\n",
    "\n",
    "    这个公式有实际的意义，$p_{click}\\cdot w_1 \\cdot p_{like}$是曝光后点赞的概率。\n",
    "    \n",
    "    1、2这两种公式都很简单，在工业界都挺常用。\n",
    "\n",
    "3. 海外某短视频APP的融合公式\n",
    "\n",
    "    $$(1 + w_1 \\cdot p_{time})^{\\alpha_1} \\cdot (1 + w_2 \\cdot p_{like})^{\\alpha_2} ...$$\n",
    "\n",
    "    $p_{time}$是预估用户观看时长，比如预估用户会观看10s，$w$、$\\alpha$ 都是超参数，需要手动调，线上做AB测试选出合适的超参数。\n",
    "\n",
    "4. 国内某短视频APP的融分公式\n",
    "    \n",
    "    多目标排序模型给n个候选视频打分，得到预估的播放时长、点击率、点赞率、转发率等指标。\n",
    "    \n",
    "    * 以预估时长$p_{time}$为例，对n篇候选视频做排序。\n",
    "    \n",
    "    * 如果某视频排名第$r_{time}$，则它得分$\\frac{1}{r_{time}^{\\alpha} + \\beta}$, $\\alpha$ $\\beta$都是需要调的超参数，预估的时长越长，排名就越靠前，$r_{time}$越小，最终的得分越高。\n",
    "    \n",
    "    * 对点击、点赞、转发、评论等预估分数做类似处理，那么一个视频会有很多排名，每一个排名变成一个分数。\n",
    "    \n",
    "    * 把每个指标的分数再求加 权和 $w_1*? + w_2*? + w_3*? +...$\n",
    "\n",
    "    与前面几个融分公式不同的是，这里不是用每个预估的分数，而是用每个分数的排名。\n",
    "\n",
    "5. 国内某电商的融分公式\n",
    "\n",
    "    * 电商的转化流程：曝光 -> 点击 -> 加购物车 -> 付款\n",
    "    \n",
    "    * 模型要预估中间每一步的转化率$p_{click}, p_{cart}, p_{pay}$\n",
    "    \n",
    "    * 最终的融分公式：\n",
    "    $$p_{click}^{\\alpha_1} x p_{cart}^{\\alpha_2} x p_{pay}^{\\alpha_3} x price^{\\alpha_4}$$\n",
    "\n",
    "    $\\alpha$是超参数，需要调，假如$\\alpha$都是1，那么这个公式就是电商的营收，有很明确的物理意义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b2571",
   "metadata": {},
   "source": [
    "## 视频播放建模\n",
    "\n",
    "讨论播放时长和完播率这两个指标\n",
    "\n",
    "图文笔记的排序和视频笔记的排序有显著的区别：\n",
    "\n",
    "* 图文笔记排序的主要依据：点击、点赞、收藏、评论、转发，也就是说用户的点击和交互反映出用户对图文笔记的兴趣。\n",
    "\n",
    "* 视频的排序依据还有播放时长和完播，尤其对于视频网站，时长和完播是最主要的指标，其次才是点击和交互。如果一个用户把视频看完，即使没有点赞和转发，也能说明用户对视频感兴趣。\n",
    "\n",
    "播放时长的预估\n",
    "\n",
    "先来讨论播放时长，它是个连续变量，自然而然会想到使用回归来拟合播放时长，但直接做回归的效果并不好，实践中对播放时长最好的建模方法是YouTube这篇论文：Deep neural network for youtube recommendations.\n",
    "\n",
    "排序模型输入用户特征、视频特征、统计特征、场景特征，经过一个多层神经网络，叫做share bottom，被所有任务共享，在这个神经网络之上，再接多个全连接层，分别对应一个目标，比如点击、点赞、收藏、播放时长，暂时我们忽略其他预估目标，只关注播放时长的预估。把全连接层输出的实数记为Z，对z做sigmoid变换，$p=\\frac{exp(z)}{1+exp(z)}$.定义y为$y = \\frac{t}{1+t}$, t为用户实际观看时长，如果没有点击，则t=0，t越大，则y越大。为了让p拟合y，用y和p的交叉熵作为损失函数，$CE(y, p) = y logp + (1-y)log(1-p)$，实践中也可以去掉分母$1+t$为$CE(y, p) = t logp + 1 \\ cdot log(1-p)$，相当于对损失函数做加权，权重是播放时长。最小化交叉熵，会让p接近y。如果p等于y，则$exp(z)=t$.对z做指数变换$exp(z)$，输出的实数就是对播放时长的预估。\n",
    "\n",
    "在训练中要用p，用y与p的交叉熵作为损失函数训练模型，做完训练之后p就没有用了，线上做推理时，只用z的指数函数，把它作为对播放时长t的预估。最终把$exp(z)$作为融分公式中的一项，会影响到视频的排序。\n",
    "\n",
    "视频完播的预估\n",
    "\n",
    "有两种建模的方法：\n",
    "\n",
    "* 回归\n",
    "    \n",
    "    例：视频长度为10min，实际播放4min，则实际完播率为y=0.4\n",
    "\n",
    "    训练时让预估播放率p拟合y：$loss = ylogp + (1-y)log(1-p)$\n",
    "\n",
    "    线上用p对完播率预估，模型输出p=0.73，意思是预估播放73%。预估的完播率会作为融分公式中的一项，影响视频的排序\n",
    "\n",
    "* 二元分类\n",
    "\n",
    "    需要算法工程师自己定义完播指标，比如完播80%\n",
    "\n",
    "    例：视频长度为10min，播放>8min作为正样本，播放<8min作为负样本\n",
    " \n",
    "    训练做二元分类：播放>80%作为正样本，播放<80%作为负样本\n",
    "\n",
    "    做完二元分类后，可以在线上预估完播率，模型输出0.73, 意思$p(播放>80%) = 0.73$，视频播放大于80%的概率等于0.73，预估的完播率会跟点击率等指标一起作为排序的依据。\n",
    "\n",
    "在实践中，不能把视频的完播率直接应用于融分公式，直觉上，视频越长，完播率越低，如果直接用完播率，那么会有利于短视频，而不利于长视频。\n",
    "\n",
    "用函数$f(播放时长)$拟合完播率，f是视频长度的函数，视频越长，函数值f越小，线上预估完播率后，然后做调整如下：$p_{finish} = \\frac{预估完播率}{f(视频长度)}$\n",
    "\n",
    "$p_{finish}$可以反映出用户对视频的兴趣，而且对长短视频是公平的，把$p_{finish}$作为融分公式中一项，与播放时长、点击率、点赞率等指标一起决定视频的排序。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4b25e",
   "metadata": {},
   "source": [
    "## 排序模型的特征\n",
    "\n",
    "现在几乎所有的工业界推荐系统都会用到用户画像和物品画像。\n",
    "\n",
    "召回和排序的模型中都有用户属性，用户属性记录在用户画像中。\n",
    "\n",
    "用户画像 (User Profile)\n",
    "\n",
    "* 用户ID是排序中最重要的特征之一（在召回、排序中做embedding），用户ID本身不携带任何有用的信息，但是模型学到的ID embedding向量对召回和排序有很重要的影响。召回和排序都会对用户ID做embedding，通常用32位或64位向量\n",
    "* 人口统计学属性，包括性别、年龄等，不同性别不同年龄段的用户，兴趣差别很大\n",
    "* 用户账号信息，包括用户注册时间、活跃度，新老用户、高活低活用户行为区别很大，模型需要专门对新用户和低活用户做优化\n",
    "* 用户感兴趣的类目、关键词、品牌，这些信息可以是用户填写的，也可以是算法自动提取的，这些用户兴趣的信息对排序也是很有用的\n",
    "\n",
    "物品画像 (Item Profile)\n",
    "* 物品ID （在召回、排序中做embedding），物品ID embedding在召回和排序中的重要性非常高\n",
    "* 物品发布时间或者物品年龄也是非常重要的特征，比如小红书，一篇笔记发布的时间越久，价值越低，尤其是明星出轨、电商打折这种强时效性的话题，热度只有几天时间\n",
    "* 物品定位的GeoHash(经纬度编码)、所在城市都对召回和排序有用\n",
    "* 笔记的内容，包括标题、类目、关键词、品牌...通常对这些离散的内容特征做embedding变成向量\n",
    "* 笔记字数、图片数、视频清晰度、标签数...这些都是笔记自带的属性，反映出笔记的质量，笔记的点击和交互指标跟这些属性相关\n",
    "* 内容信息量、图片美学...是算法打的分数，事先用人工标注的数据训练CV和NLP模型，当新笔记发布时，用模型给笔记打分，把内容信息量、物品美学这些分数写入到物品画像中，这些分数可以作为排序模型的特征\n",
    "\n",
    "除了用户画像和物品画像，排序模型还会用到用户统计特征和物品统计特征\n",
    "\n",
    "用户统计特征\n",
    "\n",
    "* 比如系统会记录用户最近30天(7天、1天、1小时)的曝光数、点击数、点赞数、收藏数...类似还会记录7天、1天、1h的，用各种时间粒度，可以反映出用户的实时兴趣，短期兴趣、中长期兴趣\n",
    "* 除此之外，还要分桶统计各种指标，比如小红书的笔记可以分为图文、视频两类，这两类分开做统计，比如最近7天，该用户对图文笔记的点击率、对视频笔记的点击率，分别做笔记，可以反映出对这两类笔记的偏好\n",
    "* 按照笔记类目做分桶，比如最近30天，用户对美妆笔记的点击率、对美食笔记的点击率、对科技数码笔记的点击率，这些统计量可以反映出用户对哪些类目更感兴趣，如果一个用户对美食笔记的点击率、点击数都偏高，说明这个用户对美食类目感兴趣\n",
    "\n",
    "物品统计特征\n",
    "\n",
    "* 跟用户统计特征类似，系统会记录每篇笔记最近30（7天、1天、1小时）的曝光数、点击数、点赞数、收藏数...这些统计量反映出笔记的受欢迎程度，如果点击率、点赞率都很高，说明笔记质量高，算法应该给这种笔记更多的流量。使用不同的时间粒度也是有道理的，有些笔记的时效性强，30天的指标很高，但是最近1天的指标很差，说明这样的笔记已经过时了，不应该给更多流量\n",
    "*  按照用户性别分桶、按照用户年龄分桶。按照笔记的受众做分桶，比如把受众分成男女两个桶，分别计算男性的点击率、女性的点击率，这样的统计量可以反映出笔记是更受男性欢迎还是更受女性欢迎，比如一篇笔记是对粉色键盘的测评，笔记总体的点击、点赞指标都很高，但是来自男性用户的点击率很低，这说明不应该把这款粉色键盘推荐给男性用户。除了性别分桶，还有年龄分桶，地域分桶等等，用途也是类似\n",
    "* 作者统计特征：\n",
    "    * 作者发布笔记数\n",
    "    * 粉丝数\n",
    "    * 消费指标（曝光数、点击数、点赞数、收藏数）\n",
    "\n",
    "    这些特征反映了作者的受欢迎程度，以及他作品的平均品质，很显然，如果一个作者的已有作品的品质普遍很高，他新发布的作品的品质大概率也会很高\n",
    "\n",
    "场景特征 （context）\n",
    "\n",
    "场景特征是随着推荐请求传来的，不用从用户画像、笔记画像数据库中获取\n",
    "\n",
    "* 用户定位GeoHash（经纬度编码）、城市，用户可能对自己附近发生的事感兴趣\n",
    "* 当前时刻（分段，做embedding），对推荐很有用，一个人在同一天不同时刻的兴趣可能有所区别，在上班路上、工作时刻、睡觉前等用户想看到的笔记可能不一样\n",
    "* 是否是周末、是否是节假日。比如节假日时，用户可能对特定话题感兴趣\n",
    "* 设备信息，比如手机品牌、手机型号、操作系统。安卓用户、苹果用户的点击率、点赞率这些指标差异非常显著，所以设备信息也是有用的特征\n",
    "\n",
    "特征处理\n",
    "\n",
    "* 离散特征：离散特征的处理很简单，就是做embedding，\n",
    "    * 用户ID，笔记ID，作者ID；数量很巨大，都是几千万、几亿的级别，消耗的内存很大。\n",
    "    * 类目、关键词、城市、手机品牌；类目也就几百个，关键词也就几百万个，给它们做embedding比较容易，消耗内存不多。\n",
    "\n",
    "* 连续特征有不同的处理方法\n",
    "    1. 做分桶，把连续特征变成离散特征，比如年龄、笔记字数、视频长度\n",
    "    \n",
    "    2. 其他变换\n",
    "        1. 曝光数、点击数、点赞数等这些指标都是长尾分布，比如大多数笔记只有几百次曝光，而极少数的笔记能有上百万次曝光，假如直接把曝光数作为特征输入模型，一旦出现几十万、几百万这种特别大的数值，计算会出现异常，比如训练时梯度会很离谱，做推理时预估值会很奇怪，所以这样的连续特征通常是做log(1+x)变换，这样会解决异常值的问题\n",
    "        2. 还可以把曝光数、点击数、点赞数这样的指标变成点击率、点赞率，并做平滑，去掉偶然性造成的波动\n",
    "\n",
    "        在实际的推荐系统中，两种变换之后的特征都作为模型的输入，比如log(1+曝光数)，log(1+点击数)会被用到，平滑之后的点击率、点赞率也会被用到\n",
    "\n",
    "\n",
    "特征覆盖率\n",
    "\n",
    "在做特征工程的时候，需要关注下特征覆盖率\n",
    "\n",
    "* 在理想的情况下，每个特征都应该覆盖100%的样本，也就是说不存在特征缺失的问题，但实际上，大多数特征都有缺失，覆盖率达不到100%，比如很多用户注册时不填写年龄，比如很多用户设置隐私权限，APP无法获取地理定位，因此场景特征有缺失\n",
    "* 做特征工程的时候，要分析特征的覆盖率，可以想各种办法提高特征覆盖率，如果一个特征很重要，提高这个特征的覆盖率，肯定可以显著提高模型的表现。除了特征覆盖率，做特征工程时，还要考虑下，当特征缺失时，用什么作为特征的默认值。\n",
    "\n",
    "数据服务\n",
    "\n",
    "推荐系统用到3个数据源，用户画像、物品画像、统计数据，3个数据源都存储在内存数据库中，在线上服务的时候，排序服务器会从3个数据源取回所需的数据，然后把读取的数据做处理，作为特征喂给模型，模型就能预估出点击率、点赞率等指标\n",
    "\n",
    "服务架构\n",
    "\n",
    "当用户刷APP时，用户请求会被发送到推荐系统的主服务器上，主服务器会把请求发送到召回服务器上，做完召回之后，召回服务器会把几十路召回的结果归并，把几千篇笔记的ID返回给主服务器。召回需要调取用户画像，这里就不展开讲了。\n",
    "\n",
    "主服务器把用户ID，笔记ID，场景特征发送给排序服务器，这里有1个用户ID和几千篇笔记ID，笔记ID是召回的结果，用户ID和场景特征都是从用户请求中获取的，场景特征包括当前时刻，用户所在的地点，以及手机的型号和操作系统，接下来排序服务器要从多个数据源取回排序所需的特征，主要是用户画像、物品画像、统计数据三个数据源，取回的是用户特征、物品特征、统计特征，用户画像数据库线上的压力比较小，因为每次只读一个用户的特征，而物品画像数据库压力非常大，粗排要给几千篇笔记做排序读取几千篇笔记的特征，同样的道理，纯用户统计值数据库的压力小，纯物品统计值的数据库压力很大，在工程实现的时候，用户画像里存什么都可以，特征可以很多很大，但尽量不要往物品画像里塞很大的向量，否则物品画像会承受过大的压力，用户画像较为静态，像性别、年龄这些属性几乎不会变化，用户活跃度、兴趣标签这些属性通常也就是天级别的刷新，变化很慢。物品画像的变化更少，可以认为是完全静态的，物品自身的属性，还有算法给物品打的标签，在很长一段时间内不会发生任何变化。对于用户画像和物品画像，最重要的是读取速度快，而不太需要考虑时效性，因为它们都是静态的。有时甚至可以把用户画像和物品画像缓存在排序服务器本地，让读取变的更快，但是不能把统计数据在本地缓存，统计数据是动态变化的，时效性很强，比如用户刷新小红书，刷了30篇笔记，点击了5篇，点赞了1篇，那么这个用户的曝光、点击、点赞都发生了变化，要尽快刷新数据库。\n",
    "\n",
    "在收集到排序所需的特征之后，排序服务器把特征打包，传给TF Serving，TensorFlow会给笔记打分，把分数返回给排序服务器，排序服务器会用融合的分数、多样性分数、业务规则给笔记做排序，把排名最高的几十篇笔记返回给主服务器，这些就是最终给用户曝光的笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ca4c4",
   "metadata": {},
   "source": [
    "# 粗排\n",
    "\n",
    "之前介绍了多目标排序模型，没有区分粗排和精排，其实前面介绍的模型主要用于精排\n",
    "\n",
    "在推荐系统的链路上，粗排在精排之前\n",
    "\n",
    "粗排、精排对比：\n",
    "\n",
    "* 粗排给几千篇笔记打分；而精排给几百篇笔记打分\n",
    "* 每做一次推荐，因为粗排要给几千篇笔记打分，单次推理的代价必须很小；而精排只给几百篇笔记打分，单次推理的代价很大也没关系，精排模型规模可以很大，模型结构可以很复杂\n",
    "* 粗排预估的准确性不高，牺牲准确性是为了线上推理的速度足够快，准确性差一些没关系，粗排的目的是做初步筛选，从几千篇笔记中选出几百篇，而不是真正决定把哪些笔记曝光给用户；精排的模型足够大，牺牲更多的计算，确保预估的准确性足够高\n",
    "\n",
    "粗排的三塔模型：参考文献Towards the next generation of pre-ranking system. 效果介于粗排和精排之间。\n",
    "\n",
    "三塔模型有三个塔，分别为用户塔、物品塔、交叉塔。用户塔的输入是用户特征和场景特征，物品塔的输入只有物品特征，交叉塔的输入包括统计特征和交叉特征，交叉特征是指用户特征和物品特征做交叉。3个塔分别输出3个向量，对3个向量做concatenate和cross，得到一个向量，把这个向量送入多个头(全连接层+sigmoid)，它们输出点击率、点赞率、收藏率、转发率的预估，训练粗排模型的方法就是正常的端到端训练，跟精排完全一样。\n",
    "\n",
    "这个模型看起来跟精排的区别不大，最主要的区别是底层的3个塔，这里是把3个塔的向量做concatenation，这个模型介于前期融合和后期融合之间。\n",
    "\n",
    "用户塔可以很大很复杂，线上每次给一个用户做推荐，用户塔只需要做一次推理，即使用户塔很大推理很慢也没有关系，用户塔对粗排总的计算量影响很小。\n",
    "\n",
    "每给用户做一次推荐，粗排需要给n个物品打分，理论上物品塔需要做n次推理，给所有n个候选物品打分，但好在物品的属性相对比较稳定，短期之内不会发生变化，可以把物品塔输出向量缓存在server，每隔一段时间刷新一次，由于做了缓存，物品塔在线上几乎不用做推理，只有遇到新物品时，物品塔才需要做推理，粗排给几千个物品打分，物品塔实际上只要做几十次推理，计算量还好，所以物品塔的规模可以比较大。\n",
    "\n",
    "交叉塔的输入是用户和物品的统计特征，还有用户和物品特征的交叉，统计特征会实时动态变化，每当一个用户发生点击等行为，他的统计特征就会发生变化，每当一个物品获得曝光和交互，它的点击次数、点击率等指标就会发生变化，由于交叉塔的输入会发生实时变化，我们不应该缓存交叉塔输出的向量，交叉塔在线上的推理避免不掉，粗排给n个物品打分，有n个物品的统计特征和交叉特征，交叉塔要实实在在做n次推理，所以交叉塔必须足够小，计算够快，通常来说交叉塔只有1层，宽度也比较小\n",
    "\n",
    "粗排给n个物品打分，模型上层需要做n次推理，无法用缓存等方式避免计算，粗排推理的大部分计算量在模型上层，模型上层做n次推理代价大于交叉塔的n次推理\n",
    "\n",
    "三塔模型的线上推理：\n",
    "* 从多个数据源提取特征\n",
    "    * 1个用户的画像、统计特征\n",
    "    * n个物品的画像、统计特征\n",
    "\n",
    "* 不论有多少个候选物品，用户塔只需要做1次推理\n",
    "\n",
    "* 物品塔输出的向量事先缓存在server上，只有当没有命中缓存时才需要物品塔做推理，最坏的情况下，物品塔需要做n次推理，但实际上缓存的命中率非常高，99%的物品都会命中缓存，不需要做推理，给几千个物品做粗排，物品塔只需要做几十次推理，\n",
    "\n",
    "* 交叉塔的输入都是动态特征，不能做缓存，必须做n次推理，3个塔各输出一个向量，把这3个向量融合起来，作为上层网络的输入\n",
    "\n",
    "* 上层网络必须做n次推理，给n个物品打分，没有办法通过缓存减小推理次数，粗排大部分的计算量都在上层网络\n",
    "\n",
    "粗排模型的设计理念就是尽量减少推理的计算量，使得模型可以在线上给几千篇笔记打分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841aca0b",
   "metadata": {},
   "source": [
    "## 特征交叉: Factorized Machine （FM）因式分解机\n",
    "\n",
    "特征交叉在召回和排序中都会用到，这里介绍最基础的Factorized Machine, 几年前FM在召回和排序中都很常用，但是现在FM已经不太常用了。\n",
    "\n",
    "线性模型，设模型用到d个特征，用d维向量x表示$x = [x_1,..., x_d]$，线性模型：$p = b + \\sum_{i=1}^{d} w_i x_i$, b是偏移项bias，线性模型的输出p是对目标的预估，为了方便，这里没有用激活函数，如果做二分类，可以用sigmoid激活函数，这个线性模型有d+1个参数为w和b，不难看出，线性模型的预测是特征的加权和，d个特征只有相加没有相乘，也就是说特征之间没有交叉。\n",
    "\n",
    "在推荐系统的应用中，特征交叉是很有必要的，可以让模型的预测更准确，线性模型+二阶交叉特征：$p = b + \\sum_{i=1}^{d} w_i x_i + \\sum_{i=1}^{d} \\sum_{j=i+1}^{d} u_{ij} x_i x_j$, 用特征交叉的话，两个特征不仅仅能相加还能相乘，这样可以提升模型的表达能力，如果有d个特征，那么模型参数量$O(d^2)$, 大多数的参数是交叉特征的权重$u$，如果d比较小，这样的模型没有问题，但如果d很大，那么参数数量就太大了，代价会很大，而且容易出现overfitting。\n",
    "\n",
    "如何减少参数数量？\n",
    "\n",
    "重点关注交叉特征的权重$u$, 可以把所有的权重$u_{ij}$组成d行d列的矩阵$U$,$U$是个对称矩阵，可以对矩阵$U$做低秩近似，用矩阵$V$乘以$V^T$，$V \\cdot V^T$来近似矩阵$U$, $V$维度是(d, k), k远小于d，k是个超参数，由我们自己设置，k越大，$V \\cdot V^T$就越接近$U$。$u_{ij}$可以近似为向量$v_i^T$和$v_j$的内积，$v_i^T$是矩阵$V^T$的第i行，$v_j$是矩阵$V$的第j行，就是U看作是$V$和$V_T$的矩阵乘法。那么模型就变成了Factorized Machine（FM）：\n",
    "$$p = b + \\sum_{i=1}^{d} w_i x_i + \\sum_{i=1}^{d} \\sum_{j=i+1}^{d} (v_i^T v_j) x_i x_j$$\n",
    "\n",
    "唯一的区别就是FM用向量$v_i^T$和$v_j$的内积作为交叉特征的权重，FM的参数数量是矩阵$V$的的大小，等于$O(kd)$,k是超参数，远比d小，FM的好处在于参数数量更少，从$O(d^2)$降低到$O(kd)$，这样使得推理的计算量更小，而且不容易过拟合。\n",
    "\n",
    "FM总结：\n",
    "* FM是线性模型的替代品，凡是能用线性回归，逻辑回归的场景都能用FM，就是在线下模型后面加上交叉项；\n",
    "* FM使用二阶交叉特征，表达能力比线性模型更强，尤其在推荐系统中，交叉特征非常有用，FM的效果显著比线性模型好；\n",
    "* 简单粗暴使用二阶交叉特征的话，参数数量是$O(d^2)$, d是特征数量，FM的好处是显著减小了参数数量，通过把$u_{ij} \\approx v_i^T v_j$，FM把参数数量从$O(d^2)$降低到$O(kd)$\n",
    "\n",
    "FM在工业界推荐系统中已经过时了，有些公司的召回和排序早就下掉了FM\n",
    "\n",
    "参考文献：Factorization Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-survival",
   "metadata": {},
   "source": [
    "## 特征交叉：深度交叉网络(DCN)\n",
    "\n",
    "DCN 既可以用于排序，也可以用于召回。\n",
    "\n",
    "召回的双塔是一种框架，而不是一种很具体的神经网络，用户塔和物品塔可以用任意的神经网络结构，最简单的模型结构自然是全连接网络，DCN网络效果比全连接网络更好。\n",
    "\n",
    "多目标排序模型中，中间的神经网络负责对特征做变换，然后输出一个特征向量，这个神经网络被所有任务共享，所以叫做shared bottom,它的网络结构可以任意，最简单的实现就是使用多个全连接层，如果用更好的神经网络结构，预估的准确性会更高。\n",
    "\n",
    "MMOE模型结构更复杂，专家神经网络用途是把各种输入的特征映射到新的特征向量，用于顶层的预估任务，专家神经网络也可以用任意的结构，包括全连接网络、深度交叉网络，还有其他结构。\n",
    "\n",
    "DCN 交叉层（Cross Layer）\n",
    "\n",
    "把输入记作$x_0$, 经过了i层之后，神经网络输出了$x_i$。第i个交叉层的结构：把向量$x_i$输入一个全连接层，全连接层输出向量$y$，把最底层的输入$x_0$与向量$y$做Hadamard product，意思是逐元素相乘，如果$x_0, y$都是8维向量，那么它们的乘积$z$也是8维的向量，向量$x_i, z$分别是输入和输出，两个向量的形状是一样的，把两个向量相加得到向量$x_{i+1}$，这个操作类似于ResNet中的跳跃连接，$x_{i+1}$是第i个交叉层的输出，$x_0, x_i$是这个交叉层的输入。这个交叉层的参数全都在全连接层里，其余的操作是向量Hadamard乘积和向量加法，都没有参数。交叉层可以写成这样的公式：\n",
    "\n",
    "$$x_{i+1} = x_0 \\circ (W \\cdot x_i + b) + x_i$$\n",
    "\n",
    "交叉层的输入是两个向量$x_0, x_i$, $x_0$是整个神经网络最底层的输入，$x_i$是神经网络第i层的输入，$W \\cdot x_i + b$是全连接层，这个全连接层的输出是个向量，跟输入的向量$x_i$的大小是一样的，$W, b$是全连接层中的参数，这个交叉层中全部的参数，参数需要在训练的过程中用梯度去更新，把向量$x_0$与全连接的输出做Hadamard乘积，也就是逐元素相承，Hadamard乘积要求左右两边的向量形状相同，最后再把Hadamard乘积的结果与向量$x_i$相加。把输入与输出相加，这就是ResNet中的跳跃连接，这是深度学习中的一种常用技巧，以防止梯度消失。左边的向量$x_{i+1}$是交叉层的输出，它的形状和$x_0, x_i$是一样的，也就是说每个交叉层的输入和输出都是向量而且形状相同。\n",
    "\n",
    "交叉网络 (Cross Network)\n",
    "\n",
    "$x_0$是交叉网络的输入，把它送进一个交叉层（参数$W_0, b_0$），交叉层输出向量$x_1 = x_0 \\circ (W_0 x_0 + b_0) + x_0$，$W_0, b_0$是这个交叉层中的参数；把上一层的输出$x_1$输入下一个交叉层(参数$W_1, b_1$)，还需要把$x_0$也输入这个交叉层，这个交叉层输出向量$x_2= x_0 \\circ (W_1 x_1 + b_1) + x_1$，重复这个过程，可以加更多的交叉层，把向量$x_2$输入下一个交叉层(参数$W_2, b_2$)，还需要把最底层的$x_0$送入这个交叉层，输出向量$x_3$,如果不加更多的交叉层，那么$x_3$就是这个神经网络的输出。\n",
    "\n",
    "上面介绍的就是DCN V2，DCN是交叉网络的原始版本，现在已经没用了。\n",
    "\n",
    "深度交叉网络 (Deep & Cross Network)意思是把普通的全连接网络和交叉网络结合起来。推荐系统召回和排序模型的输入是用户特征、物品特征、其他特征，把这些向量做concatenation，然后输入两个神经网络，全连接网络和交叉网络，两个神经网络并连，各输出一个向量，把两个向量做concatenation，输入一个全连接层，输出一个向量。全连接网络、交叉网络、全连接层都拼到一起，就是DCN，用这样的高级神经网络结构，比最简单的全连接神经网络效果更好，DCN已经被工业界普遍接受，DCN既可以用于召回，也可以用于排序，双塔模型中的用户塔、物品塔都可以是DCN，多目标排序模型中的shared bottom，MMOE中的专家神经网络都可以是DCN。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026588ab",
   "metadata": {},
   "source": [
    "# 物品冷启动\n",
    "\n",
    "## 物品冷启动：评价指标\n",
    "\n",
    "如果冷启动做的好，对整个推荐系统的帮助都很大，但是冷启动是推荐系统中最困难最复杂的一环，很难做好，整个推荐系统都很容易达到天花板，但是很少有UGC平台让冷启动达到天花板。\n",
    "\n",
    "物品冷启动的例子：\n",
    "\n",
    "* 小红书用户发布新的笔记\n",
    "* B站用户发布新的视频\n",
    "* 今日头条作者发布新的文章\n",
    "\n",
    "这都属于物品冷启动，我们主要考虑UGC (user generated content)的冷启动，内容都是用户自己上传的，小红书、油管、b站都属于UGC，跟UGC相对的是PGC (platform generated content)，像netfix，腾讯视频这些都属于PGC，主要内容是平台采购的，UGC比PGC的冷启动更难，这是因为用户上传的内容良莠不齐，差别很大，很难用人工去评判，很难让运营人员做流量调控，这里只介绍UGC冷启动怎么做。\n",
    "\n",
    "新笔记冷启动\n",
    "\n",
    "为什么要特殊对待新笔记？\n",
    "\n",
    "* 新笔记刚刚发布，缺少与用户的交互，也就是说很难根据用户的行为做推荐，这会导致推荐的难度大、效果差，如果用正常的推荐链路，新笔记很难得到曝光，即使得到曝光，效果也不好，指标会很差\n",
    "* 特殊对待新笔记的另一个原因是促进发布，大量的实验都表明，扶持新发布、低曝光的笔记，可以增强作者的发布意愿。出现首次曝光和交互的时间越快，越有利于作者的积极性，新笔记获得的曝光越多，也有利于作者的积极性\n",
    "\n",
    "出于这些原因，我们要特殊对待新发布的笔记，要对新笔记的推荐做优化。\n",
    "\n",
    "优化冷启动目标：\n",
    "\n",
    "工业界对此有共识\n",
    "* 精准推荐：冷启动首先要做到精准推荐，尽管冷启动不好做，召回和排序都有很多困难，但还是要尽量把推荐做准，把新物品推荐给合适的用户，至少不能引起用户的反感。\n",
    "* 激励发布：做法就是把流量向新笔记倾斜，让新笔记获得更多的曝光机会，这样会激励作者发布的积极性，丰富我们的内容池，特别是扶持低曝光的新笔记，对激励作者发布最有用，道理很显然，一篇笔记已经有了1w次曝光，你给它更多流量，让它曝光到2w，但这几乎不会提升作者对发布意愿，但如果是给低曝光的笔记，把曝光从20增长到100，会对作者的发布积极性有很大的帮助\n",
    "* 挖掘高潜：意思是从大量新笔记中找到质量高的，也就是有较大希望成为热门的，为了找到高质量的笔记，需要在发布初期，给每篇笔记一些曝光机会，做到雨露均沾，通过100-200次试探曝光，挖掘出潜在受欢迎的笔记，给予更多的流量倾斜，让高质量的笔记成长为热门\n",
    "\n",
    "冷启动评价指标：\n",
    "\n",
    "* 作者侧指标\n",
    "    反映出用户的发布意愿\n",
    "    * 通常用发布渗透率、人均发布量来衡量，对低曝光的笔记扶持的越好，作者侧指标就会越高\n",
    "\n",
    "    在小红书的场景下，所有用户都可以发笔记，也就是说用户也可以成为作者，作者的发布渗透率可以衡量作者的发布积极性，发布渗透率=当日发布人数／日活人数，也就是说某一天用户成为作者的比例就是渗透率。在某一天，一个用户只要发布一篇笔记，就算一个发布人数，无论是发一篇还是发10篇都算是1个发布人数。例：当日发布人数是100万，日活人数是2000w，发布渗透率=100/2000=5%\n",
    "\n",
    "    人均发布量=当日发布笔记数／日活人数，例：当日发布笔记=200w，日活人数=2000w，人均发布量=200/2000=0.1。人均发布量这个数比渗透率要大一些，因为一些作者一天会发好几篇笔记。1个作者一天发1篇或者10篇，不影响发布渗透率，但会影响人均发布量。\n",
    "\n",
    "    优化冷启动最重要的优化目标就是提高作者的发布积极性，增大内容池，对平台的发展非常有用。根据实验发现，新笔记获得的曝光越多，首次曝光和交互出现的越早，作者发布的积极性越高。所以要把流量向新笔记倾斜，让新笔记获得更多的曝光。同时也要优化新笔记的链路，让新笔记出现曝光和交互尽量快，比如把首次曝光时间从5min降低到0.5min。\n",
    "\n",
    "* 用户侧指标\n",
    "    反映出是否精准，是否会引起用户反感，用户侧指标分为两类：\n",
    "\n",
    "    * 新笔记的消费指标：新笔记的点击率、交互率。如果新笔记的推荐比较准，符合用户兴趣，这些指标会比较好看。\n",
    "        \n",
    "        但只看全体新笔记的消费指标是不够的，不能反映出真实的推荐效果，推荐系统往往存在严重的头部效应，曝光的基尼系数很大，说明少量的新笔记占据了大部分的曝光，导致全体新笔记的消费指标主要取决于少量头部的新笔记，整体的消费指标不能反映出大部分新笔记的情况，假如绝大部分新笔记都推不准，但是头部新笔记推的特别准，那么整体的消费指标也会很好，所以最好是把高曝光和低曝光新笔记分开，分别考察两者的消费指标。比如可以设计1000次曝光作为阈值，区分高曝光和低曝光，高曝光的笔记有充足的用户交互记录，即使不用冷启动技术做特殊处理，推荐系统也能做的准，我们更应该关注低曝光的新笔记。提升低曝光新笔记的点击率和交互率，一方面是因为低曝光的新笔记占比很高，绝大部分的新笔记都是低曝光，而高曝光的新笔记占比是很低的；另一方面是低曝光的新笔记的推荐不容易做好，低曝光笔记的用户交互信息很少，推荐不够准，需要设计专门的技术处理低曝光新笔记。\n",
    "\n",
    "    * 大盘指标：用户消费时长、日活、月活。做冷启动，目标不是促进消费指标增长，但冷启动的策略也不能显著伤害消费指标，应该尽量让消费指标持平。\n",
    "\n",
    "        大盘的消费指标不区分新笔记和老笔记，做新笔记推荐的实验的时候，要看大盘的指标，包括消费时长、日活、月活的用户数量，我们优化冷启动的时候，目标不是提升大盘的指标，而是要确保新的策略不会伤害大盘的指标。新笔记推荐有跷跷板效应，如果大力扶持低曝光的新笔记，给低曝光的新笔记更多的曝光，那么可以激励作者发布，让作者侧的发布指标变好，但这样会损害用户体验，让大盘消费指标变差。原因是低曝光笔记缺少用户交互，推荐做的不准，如果增加低曝光笔记的推荐，那么用户的体验会下降，造成消费时长、日活、月活的降低，所以我们做新笔记实验的时候，要考察大盘的消费指标，希望大盘的消费指标能够基本持平，确保新笔记的策略不会伤害用户的体验\n",
    "\n",
    "* 内容侧指标\n",
    "    * 高热笔记占比。高热笔记可以定义为30天内点击超过1000的笔记，这种指标能反映出冷启动是否能挖掘出优质笔记，帮助优质笔记成长为热门。\n",
    "\n",
    "    有的大厂会考察这类指标，高热笔记通常是质量高，受用户欢迎的笔记，高热笔记的占比越高越好，高热笔记占比高，说明冷启动阶段挖掘优质笔记的能力强，让优质笔记能成长起来。\n",
    "\n",
    "作者侧、用户侧指标是工业界通用的，技术比较好的大厂都会用这两类指标，内容侧指标只有少数几家在用。普通笔记的推荐通常只考察用户侧指标，而不看其他两个指标，很显然冷启动的评价体系比普通笔记要复杂很多。\n",
    "\n",
    "冷启动主要有两方面的技术，优化推荐全链路（包括召回和排序），每一个环节都针对新笔记做优化，让新笔记有足够多的机会走完链路被曝光，还要让新笔记的推荐尽量做的准，不要引起用户的反感；另一方面的技术是流量调控（流量怎么在新物品和老物品之间分配），工业界标准做法是流量向新笔记倾斜，帮助新笔记获得更多的曝光机会。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a0b47",
   "metadata": {},
   "source": [
    "## 物品冷启动：简单的召回通道\n",
    "\n",
    "有很多适用于冷启动的召回通道，这里介绍最简单的几种通道。\n",
    "\n",
    "召回的依据：\n",
    "\n",
    "笔记的信息：\n",
    "* 笔记都有图片、文字等内容，有的笔记还标注了地点。\n",
    "\n",
    "* 新笔记还有算法或人工打的标签，比如笔记的类目\n",
    "\n",
    "笔记的内容和标签都是做召回的依据，但是新笔记缺少用户点击、点赞等非常重要的信息，给推荐系统造成了很大的困难。用户对笔记的点击、点赞等数据可以反映出笔记本身的质量，以及什么样的用户喜欢这篇笔记，这对精准推荐的帮助很大，可惜新笔记没有这些信息。而且ItemCF、UserCF之类的召回通道，需要知道笔记跟哪些用户有过交互，如果一篇笔记还没有跟用户有过交互，就走不了ItemCF这种召回通道。\n",
    "\n",
    "冷启动缺少的另一个重要信息是新笔记的ID embedding，召回和排序模型都有embedding层，把每个笔记ID映射到一个向量，这个向量是从用户跟笔记交互的行为中学习出来的，冷启动的时候这个向量是刚刚初始化的，还没有用反向传播更新，也就是说新笔记的ID embedding啥都不是，反映不出笔记的特点。笔记的ID embedding是召回和排序中最重要的特征之一，缺少这个特征会让召回和排序变的很不准。 \n",
    "\n",
    "冷启动给召回带来的难点：\n",
    "* 缺少用户交互，双塔模型还没有学好笔记ID embedding，导致双塔模型的效果不好。双塔模型是推荐系统中最重要的召回通道，没有之一。离开双塔模型，很难做好新笔记的推荐。缺少笔记ID embedding，不仅会影响召回，还会影响排序，让排序模型的预估做不准。\n",
    "* ItemCF也是很重要的召回通道，想要用ItemCF就需要知道有哪些用户跟这个物品有过交互，跟新物品交互过的用户非常少，所以ItemCF对新物品不适用。\n",
    "\n",
    "    ItemCF做召回的原理是判断两篇笔记的相似度有多高，要根据笔记交互过的用户判断两篇笔记的相似度，交互过的用户重合度有多大可以反映出两篇笔记的相似度有多高。新笔记还没有跟用户发生交互，或者只跟很少的用户发生交互，ItemCF就没有办法根据重合的用户计算两篇笔记的相似度，所以ItemCF不适合冷启动。\n",
    "\n",
    "召回通道：\n",
    "* ItemCF不适用\n",
    "* 双塔模型，需要做特殊的处理\n",
    "\n",
    "    如何改造双塔模型，让它适用于冷启动？\n",
    "\n",
    "    笔记ID是物品塔中最重要的特征，神经网络有个embedding层，把笔记ID映射成向量，每篇笔记都有一个ID embedding向量，需要从用户和笔记的交互中学习，可是新笔记还没有跟几个用户交互过，所以它的embedding向量还没有学好，如果直接用双塔模型做新笔记的召回，效果会不太好。\n",
    "\n",
    "    改进ID embedding的方案一：\n",
    "    \n",
    "        新笔记使用default embedding，物品塔做ID embedding时，让所有新笔记共享一个ID，而不是用新笔记自己真正的ID，那么所有新笔记的ID embedding向量都是相同的，这个向量叫做default embedding，使用default embedding在实践中是可以拿到收益的。因为新笔记的ID embedding向量还没有学到，不如大家先共享一个默认的向量，这个向量是学出来的，而不是随机初始化或者全零初始化，学出来的default embedding比随机初始化或全零初始化更好。新笔记发布之后，逐渐会有点击和交互，这些信号可以用来学习笔记的ID embedding，到下次模型训练的时候，新笔记的ID embedding才被学到。\n",
    "    \n",
    "    改进ID embedding的方案二：\n",
    "\n",
    "        另一个初始化新笔记的ID embedding的方法是利用相似物品的embedding向量，当新笔记发布之后，查找top-k内容相似的高曝光笔记，相似可以用图片、文字、类目来定义，用多模态神经网络把一篇笔记的图文内容表征为一个向量，每当一篇新笔记发布的时候，寻找最相似的k个向量，把找到的k个高曝光笔记的embedding向量取平均，作为新笔记的embedding。之所以用高曝光笔记，是因为它们的ID embedding通常学的比较好。\n",
    "\n",
    "    在实践中，通常会用多个向量召回池，比如1h新笔记、6h新笔记、24h新笔记、30天老笔记，用多个召回池，可以让新笔记有更多的机会曝光，假如只有1个30天笔记的召回池，那么新笔记被召回的几率很小，很难得到曝光。所有这些召回池用的是同一个双塔模型，所以不会增加训练模型的代价。\n",
    "\n",
    "* 类目、关键词，是两个弱个性化的召回通道，在笔记刚刚发布时，这两个召回通道是最有用的，但是在笔记发布过一段时间之后，这两种召回通道会失效\n",
    "\n",
    "    凡是做信息流、社交、电商的互联网公司，都会维护每一个用户的画像，画像中记录了用户的兴趣点，比如感兴趣的类目、感兴趣的关键词，有的是用户自己填写的，有的是算法自动推断出来的，这些类目和关键词可以用于召回。\n",
    "    \n",
    "    基于类目的召回通道：\n",
    "\n",
    "    * 系统维护类目索引:  类目 -> 笔记列表(按时间倒排)\n",
    "\n",
    "        在小红书，系统维护一份类目到笔记的索引，索引的key是类目，比如美食、美妆、旅游这样比较大的类目，也可以是更细粒度的类目，比如日本料理，国内旅游，护肤品这样的类目，每个类目的后面是一个笔记的列表，按照发布时间倒排，最新发布的笔记排在最前面。\n",
    "\n",
    "    * 用类目索引做召回：用户画像 -> 类目 -> 笔记列表\n",
    "        \n",
    "        一个用户刷新APP的时候，系统要给他做推荐，系统根据这个用户的画像，知道他对哪些类目感兴趣，取回这些类目，比如对美食和旅游感兴趣，然后到类目索引上找到旅游和美食对应的笔记列表\n",
    "    \n",
    "    * 取回笔记列表上前k篇笔记（即最新的k篇）\n",
    "\n",
    "        分别得到美食和旅游的前k篇笔记，这样得到2k篇笔记，做为召回的结果\n",
    "\n",
    "    基于关键词的召回：\n",
    "\n",
    "    * 系统维护关键词索引： 关键词 -> 笔记列表（按时间倒排）\n",
    "\n",
    "        索引的key是关键词，每个关键词后面有个笔记列表，按照时间倒排\n",
    "\n",
    "    * 根据用户画像上的关键词做召回\n",
    "\n",
    "        给用户做推荐的时候，根据用户画像上用户感兴趣的关键词做召回\n",
    "\n",
    "    跟类目召回唯一的区别，这里用关键词代替类目\n",
    "\n",
    "    这两种召回通道都有很明显的缺点：\n",
    "    1. 只对刚刚发布的新笔记有效。类目索引和关键词索引都是按照笔记发布的时间倒排，刚刚发布的新笔记排在最前面，做召回的时候，取回某类目／关键词下最新的k篇笔记，如果笔记已经发布了几小时，那么大概率会被排在几百甚至几千的位置上，也就是说这篇笔记再也没有机会被召回了。这两个召回留给每个笔记的窗口期很短。\n",
    "    2. 弱个性化，不够精准。按照用户感兴趣的类目／关键词做召回，其实是比较宽泛的，假如用户喜欢观赏鱼，属于宠物的类目，但是最新发布的宠物类目笔记可能都是猫猫狗狗的，大概率没有用户感兴趣的观赏鱼，于是召回了100篇都是用户不感兴趣的。\n",
    "\n",
    "    虽然类目、关键词召回的缺点很明显，但它们仍然对冷启动很重要，它能让刚刚发布的新笔记立刻获得曝光，有助于提升作者的发布积极性。\n",
    "\n",
    "\n",
    "* 聚类召回\n",
    "\n",
    "    聚类召回是基于笔记的图文内容做推荐，聚类召回在物品冷启动时特别有用。\n",
    "\n",
    "    基本思想：\n",
    "\n",
    "    * 如果用户喜欢一篇笔记，那么他会喜欢内容相似的笔记。假如用户收藏了一篇在上海买房的笔记，系统给用户推了更多上海买房的笔记，用户有可能会点开。\n",
    "\n",
    "    * 我们需要判断两篇笔记的内容相似度，可以用神经网络来做，事先训练一个神经网络，基于笔记的类目和图文内容，把笔记映射到向量，向量的相似度就是笔记内容的相似度\n",
    "\n",
    "    * 对笔记向量做聚类，划分为1000个cluster，记录每个cluster的中心向量。对笔记向量做聚类，所以这种召回通道叫做聚类召回，可以用k-means聚类，聚类时需要指定一个相似度，比如用余弦相似度。\n",
    "\n",
    "    聚类召回通道有一个索引，当新笔记发布时，新笔记就会上索引\n",
    "\n",
    "    * 当一篇新笔记发布之后，用神经网络把它的图文内容映射到一个特征向量\n",
    "    * 然后把这个特征向量去跟1000个cluster中心向量做比较，找到最相近的向量做为新笔记的cluster，新笔记绑定了一个cluster\n",
    "    * 索引： cluster -> 笔记ID列表（按时间倒排）。把新笔记的ID添加到索引上，索引是cluster到笔记ID列表，一共有1000个cluster，每个cluster是笔记ID列表，列表是按照笔记的发布时间倒排的，最新的笔记排在最前面。\n",
    "\n",
    "    线上召回\n",
    "\n",
    "    * 有了索引，就可以在线上做召回，当一个用户刷APP发起推荐的请求，系统就要用他的ID找到他的last-n记录，包括点赞、收藏、转发的笔记列表，把这些笔记做为种子笔记，去召回相似的笔记\n",
    "\n",
    "    * 用神经网络把每篇种子笔记映射到特征向量，然后与1000个中心向量做比较，寻找最相似的cluster，这样做完，系统就知道用户对哪些cluster感兴趣\n",
    "\n",
    "    * 从每个cluster的笔记列表中，取回最新的m篇笔记\n",
    "\n",
    "    * 这样的话，最多取回mn篇笔记\n",
    "\n",
    "    聚类召回和类目召回有相同的缺点，都是只对刚刚发布的新笔记有效，一篇笔记发布1-2h后，就不太可能被召回了。\n",
    "\n",
    "    聚类召回需要调用一个神经网络，把笔记图文内容映射到一个向量，如果两篇笔记的内容相似，那么两篇笔记的向量就应该有较大的余弦相似度\n",
    "\n",
    "    内容相似度模型\n",
    "\n",
    "    以小红书的图文笔记为例，笔记中有几张图和几段文字，这里只考虑最简单的情况，笔记中只有一张图：\n",
    "    * 用CNN提取图片的特征，得到一个向量\n",
    "    * 用BERT提取文字的特征，得到另一个向量\n",
    "    * 把两个向量做concatenation，输入全连接层，神经网络输出一个向量，这个向量是对笔记图文对表征，如果两篇笔记内容相似，它们的向量会相似\n",
    "\n",
    "    两篇笔记内容相似度\n",
    "\n",
    "    比如有两篇笔记，各自都有图片和文字，把左边的笔记输入刚才的神经网络，得到笔记的特征向量a，同样的操作，把右边的笔记得到另一个特征向量b，这两个神经网络的参数是相同的，计算两个向量夹角的余弦相似度，得到一个介于（-1，1）之间的数，衡量两篇笔记有多相似。搭好模型之后，需要训练模型，模型中的BERT是预训练好的，可以固定BERT的参数，也可以做finetune，怎么样都可以。CNN也是预训练好的，比如用ImageNet数据集上预训练好的神经网络，可以做finetune更新CNN的参数。全连接层是随机初始化的，需要从数据中学习，\n",
    "\n",
    "    训练内容相似度模型\n",
    "\n",
    "    训练的方法和双塔模型比较类似，每个训练样本都是一个三元组，（正样本笔记，种子笔记，负样本笔记），把三篇笔记输入神经网络（CNN+BERT+FC），神经网络输出三个向量$b^+, a, b^-$, 分别对应正样本笔记、种子笔记、负样本笔记，计算向量$b^+$和$a$的余弦相似度$cos(a, b^+)$，表示种子笔记和正样本的内容相似度，越大越好，再计算$cos(a, b^-)$，表示种子笔记和负样本之间的相似度，数值越小越好。\n",
    "\n",
    "    基本思想：鼓励$cos(a, b^+)$大于$cos(a, b^-)$\n",
    "    \n",
    "    做训练的目标是让种子笔记预正样本的相似度尽量大，让种子笔记与负样本的相似度尽量小，也就是让两个余弦相似度的差尽量大。\n",
    "\n",
    "    Triplet hinge loss：\n",
    "    \n",
    "    $$L(a, b^+, b^-) = max{0, cos(a, b^-)+m-cos(a, b^+)}$$\n",
    "\n",
    "    最小化Triplet hinge loss，会鼓励种子和正样本的相似度尽量大，种子和负样本的相似度尽量小\n",
    "\n",
    "    Triplet logistic loss:\n",
    "\n",
    "    $$L(a, b^+, b^-) = log(1 + exp(cos(a, b^-) - cos(a, b^+)))$$\n",
    "\n",
    "    作用和hinge loss是一样的，通过最小化损失函数来学习神经网络参数。\n",
    "\n",
    "    (种子笔记, 正样本)选取：\n",
    "\n",
    "    方法一：\n",
    "\n",
    "        正样本就是相似度高的笔记，最直接的方法就是人工标注二元组的相似度，这样就得到了正样本，但是人工标注的代价太大，不划算\n",
    "\n",
    "    方法二：\n",
    "\n",
    "        算法自动选取正样本，代价比较小，设置这样的筛选条件\n",
    "\n",
    "        筛选条件：\n",
    "\n",
    "            * 只用高曝光的笔记作为二元组，因为高曝光的笔记有充足的用户交互信息，算法选择的正样本会比较准\n",
    "            * 两篇笔记有相同的二级类目，比如都是菜谱教程，做这样一道筛选，可以过滤掉完全不相似的笔记\n",
    "        \n",
    "        最后用ItemCF的物品相似度选择正样本。\n",
    "\n",
    "    （种子笔记， 负样本）选取：\n",
    "\n",
    "        * 负样本选择很容易，直接从全体笔记中随机选出满足条件的：\n",
    "            * 字数较多，这样的话神经网络提取的文本信息比较有效\n",
    "            * 笔记质量高，避免图文无关的劣质笔记\n",
    "\n",
    "    聚类召回总结：\n",
    "\n",
    "    基本思想：根据用户的点赞、收藏、转发记录，推荐内容相似的笔记\n",
    "    \n",
    "    线下训练：想做聚类召回，需要线下训练一个多模态神经网络，可以把图文内容映射到向量，通过比较向量的余弦相似度，就知道哪两个向量最相似\n",
    "    \n",
    "    线上服务：用户喜欢的笔记 -> 特征向量 -> 最近的cluster —> 新笔记\n",
    "\n",
    "        线上服务时，根据用户记录中喜欢的笔记，召回相似的新笔记。首先把用户历史喜欢的笔记输入给神经网络，计算出一个特征向量，然后把特征向量跟1000个cluster中心向量比较，找到最相似大中心向量，选择这个cluster，每个cluster都有一个笔记列表，按照时间顺序倒排，选择列表上前几篇笔记，也就是最新的几篇作为召回结果。\n",
    "\n",
    "* Look-Alike 人群扩散召回\n",
    "    \n",
    "    聚类召回和Look-Alike是专门针对新物品的召回通道。\n",
    "\n",
    "    Look-Alike本身起源于互联网广告，是互联网广告中常用的一类方法。\n",
    "\n",
    "    假设一个广告主Tesla想要精准地给100w个目标投放广告，他们自己知道Model3的典型用户是这样的：年龄在25-35，都是年轻人；受过良好教育，学历至少都是本科；车主大多关注科技数码；而且普遍喜欢苹果的点子产品。把符合全部条件的用户都圈出来，重点在这个人群中投放广告，满足所有条件的受众被称作种子用户，这样的用户数量可能不会很多，只有几万人，但是潜在的符合条件的用户可能会很多，但是我们缺少他们的部分信息，没有办法找到他们，比方说多数的用户不标自己的学历和年龄，广告主想给100w用户投放广告，但我们才圈出几万人，该如何发现潜在的100w目标用户呢？这就要用到Look-Alike人群扩散，寻找跟种子用户相似的用户，把找到的用户称作Look-Alike用户，通过这种方式，可以利用几万个种子用户找出几十万个Look-Alike用户。\n",
    "\n",
    "    Look-Alike只是一个框架，具体该怎么计算，有各种各样的算法，最重要的问题在于如何定义两个用户之间的相似度？有很多简单的方法：\n",
    "    \n",
    "    * UserCF：以两个用户共同的兴趣点衡量两个用户的相似度，要是两个用户同时对许多相同的物品感兴趣，说明两个用户的相似度比较大\n",
    "    * ID embedding：用两个用户的ID embedding向量的夹角的cosine值\n",
    "\n",
    "    Look-Alike 用于新笔记召回：\n",
    "\n",
    "    在冷启动的场景下，Look-Alike的思想是这样的：如果用户有点击、点赞、收藏、转发等行为，说明用户可能对笔记感兴趣。把有点击、点赞、收藏、转发等交互行为的用户作为新笔记的种子用户，我们知道这些种子用户对新笔记感兴趣，如果一个用户跟种子用户相似，那么他也可能对这篇笔记感兴趣，可以把新笔记推荐给他，这种方法就叫Look-Alike人群扩散。根据种子用户找出更多兴趣相似的用户，把新笔记从种子用户扩散到更多Look-Alike用户。\n",
    "\n",
    "    用户在APP上发布一篇新笔记，系统会把新笔记推荐给很多用户，少数用户会对笔记感兴趣，会点击、点赞、收藏、转发，把这些用户称作种子用户，系统对新笔记的推荐通常不太准，有交互行为的用户数量很少，一旦有交互行为，我们要充分利用这种信号，让推荐变得更准。取回每个种子用户的embedding向量，可以复用双塔模型学到的用户向量，然后取这些种子用户向量的均值，得到一个向量，把这个向量作为新笔记的表征，反映出什么样的用户对该笔记感兴趣，这个特征向量是要做近线更新的，近线是指不用实时更新，能做到分钟级的更新就可以。每当有用户交互该笔记，就得把新用户的向量加进去，更新一下该笔记的特征向量，也就是交互发生几分钟更新笔记的特征向量。在线实时更新还做不到，也没有必要在几秒内就更新特征向量。\n",
    "\n",
    "    把新笔记的特征向量都放在向量数据库里，都支持最近邻查找。如果有用户刷一下App，就给这个用户做一次推荐，用双塔模型计算这个用户的特征向量，拿用户的特征向量作为query，在向量数据库中做最近邻查找，取回几十篇笔记，这个召回通道就叫Look-Alike.\n",
    "\n",
    "    这种方法应用在推荐系统，特别是召回低曝光笔记，在有些大厂落地应用中取得了不错的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c33516",
   "metadata": {},
   "source": [
    "## 物品冷启动：流量调控\n",
    "\n",
    "做冷启动，最重要的抓手有两个，一个是优化推荐全链路，包括召回和排序，每一个环节都针对新笔记做优化，让新笔记有足够多的机会走完链路被曝光，还要尽量让新笔记的推荐做的准，不要让用户反感；另一个抓手是流量调控，也就是流量怎么在新笔记和老笔记中分配，工业界常用的做法是让流量向新笔记倾斜，帮助新笔记获得更多的曝光机会。\n",
    "\n",
    "扶持新笔记主要有两个目的：\n",
    "\n",
    "* 促进作者发布，增大内容池\n",
    "\n",
    "    新笔记获得的曝光越多，作者的创作积极性就越高，把流量向新笔记倾斜，可以观测到发布渗透率和人均发布量的提升\n",
    "\n",
    "* 挖掘优质笔记\n",
    "\n",
    "    假如一篇笔记没有获得几次曝光，即使笔记的质量特别高，系统也没有办法发现这是篇优质笔记，不会给这篇笔记更多的流量让它变成热门笔记，所以要保证每篇新笔记在初始的探索阶段都能获得足够多的曝光，比如获得100次曝光。如果冷启动做的好，能更好的挖掘出优质笔记，那么高热笔记的占比会提高，比如点击1000次以上的笔记占比会更高。\n",
    "\n",
    "工业界做法：\n",
    "\n",
    "假设推荐系统只分发年龄<30天的笔记，超过30天的笔记通常不会出现在推荐的结果里，只能通过搜素和其他渠道曝光。假设采用自然分发，让新老笔记公平竞争，那么年龄小于24h的新笔记的曝光就会非常小，只有1/30. 但我们会给新笔记大力度大扶持，让新笔记有足够多的机会曝光，占比远远大于1/30。也就是说新笔记的流量远远大于自然分发的流量。\n",
    "\n",
    "业界的流量调控技术大致有这几个发展阶段：\n",
    "\n",
    "1. 最原始的流量调控技术是在推荐结果中强插新笔记，让新笔记获得额外的曝光机会。某些大厂的边缘业务线现在还在用这种落后的技术。\n",
    "\n",
    "2. 提权 boost：在做排序的时候，给新笔记的分数做boost，比如加上或者乘以一个系数，这样会让新笔记更占优势，获得更多的曝光机会，给新笔记提权是投入产出比很划算的策略，实现起来也不难，效果还可以，像抖音、小红书前期都这么做\n",
    "\n",
    "    纯粹用自然分发，曝光的笔记中，年龄小于24h的新笔记应该占1/30，如何让新笔记占到更多的曝光呢？那么就必须做人为干涉，在哪个环节干涉呢？显然是干涉粗排和重排，这两个环节是漏斗，会过滤掉大量笔记，干涉的方法就是对新笔记提权，让新笔记比老笔记更有优势，有更多的机会通过漏斗。\n",
    "    \n",
    "    目标：让新笔记有更多机会曝光\n",
    "        * 如果做自然分发，24h新笔记占比为1/30\n",
    "        * 做人为干涉，让新笔记占比大幅提升\n",
    "\n",
    "    优点：给新笔记提权容易实现，可以用小的投入获得比较好的产出，在前期没有足够多的人力的情况下，这种方案比较好\n",
    "\n",
    "    缺点：这种方案需要人为设置一些提权系数，把它们乘到排序模型打的分数上，曝光量对提权系数很敏感，系数大一点，可能会把很多低质量的新笔记排在前面，系数小一点，给新笔记的曝光可能不足。造成很难精确控制曝光量，需要仔细调参数，但是调的再细也做不到精准控制曝光量，肯定会发生过度曝光和不充分曝光。\n",
    "\n",
    "3. 保量：比如尽量保证每篇新笔记都能在前24h获得至少100次曝光，保量的手段也是提权，但是提权的策略更复杂，更精细\n",
    "\n",
    "    对于一篇新笔记，不论笔记质量高低，不论笔记是什么内容，都尽量保证它在前24h获得100次曝光。最原始的保量方法是在原有提权系数的基础上，再乘以额外的提权系数，帮助笔记在24h获得100次曝光。需要差异化对待不同的发布时间、不同的曝光次数的笔记，离100次曝光差的越多，提权系数就越大，争取给笔记更多的曝光机会，比如等比例来算，12h应该获得50次曝光，如果12h达到50次曝光，那么提权系数就是1，不给额外的扶持，假如12h只获得20次曝光，那么就应该加大扶持力度，提权系数是1.2，真正做保量时，需要仔细调权重才行。\n",
    "\n",
    "    动态提权保量：更先进的保量做法，用4个值计算提权系数\n",
    "\n",
    "    * 目标时间：比如24h\n",
    "    * 目标曝光：比如100次\n",
    "    * 发布时间：比如笔记已发布12h\n",
    "    * 已有曝光：比如笔记已获得20次曝光\n",
    "\n",
    "    可以用这样的函数动态计算提权系数：\n",
    "\n",
    "    $$提权系数 = f(\\frac{发布时间}{目标时间}, \\frac{已有曝光}{目标曝光}) = f(0.5, 0.2)$$\n",
    "\n",
    "    这里0.5, 0.2是上面的例子，第一个变量越大，第二个变量越小，提权系数应该越大。\n",
    "\n",
    "    保量看起来简单，只需要把提权系数调好就行了，但实际操作起来，并不容易，成功率远低于100%，也就是说很多新笔记在24h达不到曝光100次。造成保量失败的原因可能有很多种，有可能是链路上存在问题，比如新笔记的召回做的不好，有些类型的新笔记很难被召回，就算提权系数再高，这样的新笔记也很难获得曝光；也有可能是排序模型的问题，对新笔记的预估做的不准；还有可能是新笔记的提权系数没有调好，导致曝光不足；即使把链路和提权系数都优化好了，线上环境的变化也会导致保量的失败，推荐系统总是在不断升级迭代中，比如添加新的召回通道，比如升级了排序模型，比如改变了重排打散的规则，这些变化都有可能导致保量失败，线上环境变化后，往往需要调整提取系数，很麻烦。\n",
    "\n",
    "    思考题：给所有新笔记一个很大的提权系数，比如4倍，一直给到达成100次曝光为止，有的笔记20min就达到曝光100次，有的笔记10h达到曝光100次，只要一篇新笔记达到曝光，就不再做提权，把它跟老笔记同等对待。很显然，这种很大的提权系数，保量的成功率会很高，问题来了，既然这样的保量成功率很高，为什么不用这种简单的方法，而是用更精细更复杂的提权方法呢？\n",
    "\n",
    "    因为这种简单粗暴的方法不好，是不是给新笔记分数boost越多，对新笔记越有利呢？假如把一篇笔记的分数乘以2，笔记的排序位置就会更高，获得更多的曝光，也就是说在笔记冷启动阶段，分数提升越多，对新笔记的曝光次数越有利，但是过了冷启动阶段之后，之前大力度的扶持可能会起到反作用，如果不要人为去提高预估分数，那么只有当遇见匹配受众的的时候，预估分数才会高，笔记才能通过排序的筛选，最终曝光给用户，假如人为大幅提升笔记的分数，那么笔记很容易通过排序的筛选，哪怕笔记不是用户特别感兴趣的话题，把笔记推荐给不太合适的受众会有什么后果呢？很显然，这样会对点击率、点赞率等指标造成负面的影响，给笔记分数提升的越狠，越会让笔记展示给不合适的受众，对点击率、点赞率越不利，如果点击率、点赞率这类数值比较低，那么笔记会长期受推荐系统的打压，曝光会很少，本来有潜力成为热门的物品，最终没有成长起来。所以粗暴地给新笔记提权，对新笔记并不好，这也是为什么做保量时要很仔细地调保量的系数。\n",
    "\n",
    "4. 差异化保量：在笔记刚刚发布的时候，根据内容质量决定保量的目标是多少次曝光，内容质量高的，保量的目标定的高，给更多的流量倾斜\n",
    "\n",
    "    保量：简单的保量是不论新笔记质量高低，都做扶持，目标是在前24h给100次曝光\n",
    "\n",
    "    差异化保量：不同笔记有不同的保量目标，比如普通笔记保100次曝光，优质内容的笔记保100-500次曝光，具体的保量目标由算法判定。\n",
    "\n",
    "    做法：\n",
    "\n",
    "    每篇笔记都有一个基础保量，比如24h保100次曝光，差异化保量的依据是笔记内容的质量、作者的质量。对于内容质量，可以用多模态神经网络判定图文视频的质量高低，在新笔记发布的时候，根据模型的预测，给新笔记额外的保量，比如说最多给200次额外的保量；如果一个作者以前发布的笔记普遍质量比较高，那么他发的新笔记也大概质量比较高，应该给予额外的保量目标，比如最多增加200次额外的保量。如果这样做差异化保量，那么一篇新笔记在前24h至少保100次曝光，最多保500次曝光，达到保量目标之后，就会停止扶持，让新笔记自然分发，跟老笔记公平竞争。\n",
    "\n",
    "    差异化保量有助于扶持高质量的笔记，对整个生态是有利的。\n",
    "\n",
    "    动态保量和差异化保量算不上业界的顶尖技术，但也算是先进的技术，只有技术很好的大厂核心部门才能做到，非核心部门或者二线互联网公司是做不到的。做保量的坑很多，但值得尝试。根据业界的经验，如果能把保量的技术做好，对发布侧的指标会有非常大的提升。\n",
    "\n",
    "扶持新笔记的两个抓手：单独的召回通道、在排序阶段提权"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b6134",
   "metadata": {},
   "source": [
    "## 物品冷启动： AB测试\n",
    "\n",
    "想要上线新的模型或者策略，需要做AB测试。冷启动的AB测试特别复杂，远比正常推荐系统AB测试麻烦。\n",
    "\n",
    "在小红书场景下，做冷启动的AB测试，既要看作者侧指标，又要看用户侧指标。\n",
    "\n",
    "作者侧指标：发布渗透率、人均发布量，反映出作者的发布意愿，如果冷启动做的好，可以激励作者，让渗透率和发布量增长，用AB测试考察作者侧指标是比较困难的。\n",
    "\n",
    "用户侧指标：对新笔记的点击率、交互率。如果冷启动的推荐做的越精准，用户对推荐的新笔记越感兴趣，那么新笔记的点击率和交互率就会越高。除此之外，还要看大盘的消费指标，比如消费时长、日活、月活。不希望冷启动推荐的新笔记引起用户反感，导致用户不活跃，大盘指标下跌。\n",
    "\n",
    "标准的AB测试通常只测试用户侧指标，实验比较好做，而冷启动的AB测试需要测很多指标，很麻烦。\n",
    "\n",
    "推荐系统标准的AB测试：\n",
    "\n",
    "把用户随机分为两组，实验组、对照组，每组有50%的用户，右边是全体的笔记，物品组。给实验组用户做推荐，会从全量的笔记池中选出最合适的笔记，当实验组用户发起推荐请求的时候，会用新的策略。给对照组用户做推荐，也是从全量的笔记池中选出最合适的笔记，如果一个用户属于对照组，给他做推荐的时候，用旧的策略。在实验的过程中，对比两组用户消费指标的diff，比如考察用户消费推荐内容的时长，发现实验组比对照组高了1%。\n",
    "\n",
    "冷启动的AB测试要测两类指标，用户侧消费指标和作者侧的发布指标。\n",
    "\n",
    "用户侧实验\n",
    "\n",
    "推荐系统标准的AB测试方法可以用于冷启动，考察用户侧的消费指标，比如考察策略对新笔记CTR的diff、对用户消费时长的diff，但这种AB测试的设计有不足之处，问题不严重，这样的AB测试结果还算可行。\n",
    "\n",
    "缺点：做一个限定，假设冷启动流量调控机制要求做保量，要尽量给新笔记100次曝光，再做个假设，新笔记曝光越多，用户使用APP的时长就会越低，这个假设很合理，通常来说，新笔记推荐不够准，新笔记太多会影响体验。现在实验一个新策略，在排序的时候给新笔记提权，让权重增大2倍，这样会让更多的新笔记曝光，很显然这个新策略会伤害用户体验，导致消费指标变差。如果只看消费指标，那么AB测试的结果是负向的，diff是负数，策略组不如对照组。如果把实验推全，也就是对所有的用户都上新策略，diff会缩小，也就是说新策略对用户的伤害没有AB测试观测到的那么严重，比如AB测试观测的diff是-2%，可能推全之后，消费指标只跌了1%。为什么呢？给实验组提权2倍，那么实验组看到的新笔记会变多，实验组的消费指标会变差，保量100次的曝光是确定的，既然新笔记中，实验组那里得到更多的曝光，那么从对照组得到的曝光就会减少，对照组的消费指标会变好，实验组变差，对照组变好，这就导致AB测试观测到的diff很大，但推全后，消费指标实际上跌不了那么多。\n",
    "\n",
    "作者侧实验\n",
    "\n",
    "作者侧的实验不太好做，没有很完美大实验方案\n",
    "\n",
    "方案一：\n",
    "\n",
    "全体用户，不对用户做分组，全体老笔记，不对老笔记做分组，但要区别对待老笔记和新笔记，新笔记按照作者随机分为两组，实验组和对照组，这样可以对比作者的发布积极性，知道新的策略能不能激励发布。老笔记完全是自然分发，不受新旧策略的影响，从全量的老笔记中选出用户最喜欢的推荐给用户。新笔记的实验组用新策略，这些新笔记有机会触达所有用户，对照组用旧策略，也有机会被任何一个用户看到。例子：对照组是简单的保量，不论笔记质量的好坏，都保200次曝光，实验组是差异化保量，100次曝光的基础保量，外加给优质内容、优质作者的额外保量，最多给500次曝光，最后对比这两组作者的发布指标，就知道哪种策略对发布更有利。\n",
    "\n",
    "这种作者策略的AB测试方案有个严重的缺点，主要在于两组新笔记之间会抢流量，存在这种可能性，实验观测到diff，比方说作者的发布指标涨了2%，但是推全之后，发布指标没有发生任何变化，为什么会出现这种现象？设定：新老笔记走各自的队列，各自做排序各自做截断，新老笔记之间没有竞争，重排分配给新笔记1/3流量，分给老笔记2/3流量，两者的曝光占比是固定不变的，现在上一个新策略，把新笔记重排时的权重增大2倍，在我们的设定下，这种新策略不会产生任何影响，新笔记只跟新笔记竞争，不跟老笔记竞争，如果把所有新笔记的权重都乘以2，那么新笔记之间还是公平竞争，跟原先没有区别，新笔记的曝光占比还是1/3，所以新策略不会激励发布，不会改变发布侧指标，但是AB测试的结果显示有正向收益，如果看发布侧指标，比如看发布渗透率，发现实验组优于对照组，这是不合理的，为什么会出现这种不合理的现象？实验组给新笔记提权，对照组没有提权，实验组的新笔记会抢走对照组的曝光，那么实验组的发布指标会涨，对照组的发布指标会跌，这样就产生了diff，从AB测试的结果来看，新策略有正向收益，但是在我们的设定下，给新笔记权重乘以2是不会影响发布指标的，很显然把新策略推全之后，发布侧指标跟以前相比还是完全一样，这个例子说明方案一有严重缺陷，AB测试观测到的diff是不可信的，推全之后可能会消失，这种缺陷是新笔记之间抢流量造成的，如果给实验组新笔记提权，那么实验组就能抢到更多的曝光机会，相应的，对照组新笔记得到的曝光就会减少，这样两组的发布指标就会产生diff，如果把新策略推全，给所有新笔记都提权，那么就不存在两组之间抢流量的情况，就不会出现diff。\n",
    "\n",
    "这种方案还有1个缺点，就是新笔记和老笔记可能会抢流量，如果让新老笔记自由竞争，那么50%的新笔记提权之后，会抢100%老笔记的流量，平均1份新笔记抢走2份老笔记的流量，如果推全，那么就是100%的新笔记抢100%的老笔记的流量，1份新笔记只抢走1份老笔记的流量，也就是说推全之后，新笔记更难抢到流量。新老笔记之间抢流量不是问题，问题在于AB测试和推全之后设定发生了变化，导致AB测试的结果不准确。设定：新老笔记自由竞争，不控制新老笔记的曝光占比，这里的设定和前面的不一样。新策略：把新笔记排序时的权重增大2倍，让新笔记更有优势。AB测试时，50%的新笔记带策略跟100%的老笔记抢流量，1份新笔记可以抢走2份老笔记的流量，推全后，设定发生了变化，所有的新笔记都带策略，跟所有的老笔记抢流量，1份新笔记只能抢走1份老笔记的流量。由于设定发生了变化，AB测试的结果和推全之后的结果是有差异的。比如AB测试的结果是发布渗透率涨了2%，推全后可能大盘的发布渗透率只涨了1%。\n",
    "\n",
    "方案二：\n",
    "\n",
    "跟上一种方案的区别是用户被分为了2组，实验组和对照组，实验组的用户只能看到实验组的新笔记，对照组的用户只能看到对照组的新笔记，这种设计的目的是避免两组新笔记抢流量，因此这种方案比方案一的结果更可信，这种方案也有缺点，最大的问题在于内容池减小了，50%的用户只能看到50%的新笔记。原本一个用户在刷APP时，推荐会从全体的新笔记中选出100篇最符合用户兴趣的，现在新笔记的内容池小了一半，100篇最符合兴趣的笔记只剩了50篇，要从差一些的笔记中再选出50篇补上来，这肯定会影响用户体验，造成消费侧指标下跌，也就是说为了做个AB测试，导致大盘变差，公司的业务会受损失。\n",
    "\n",
    "方案二 VS 方案一：\n",
    "\n",
    "优点：同时隔离作者和新笔记，这样做的话，新笔记的两个桶不会抢流量，这样做会让作者侧的实验结果更可信，如果AB测试观测到发布指标有diff，那就说明确实会有diff，推全之后diff不会消失。\n",
    "\n",
    "缺点：两个方案共同的缺点是新笔记和老笔记抢流量，AB测试的时候50%的新笔记跟100%的老笔记抢流量，1份新笔记抢走2份老笔记的流量，推全之后，全量的新笔记和全量的老笔记抢流量，一份新笔记抢走一份老笔记的流量，这会导致AB测试的结果与推全之后的结果有差异。跟方案一相比，方案二有个缺点，做隔离之后，每个用户对应的笔记池都小了一半，这会让推荐的结果变差，对用户体验造成负面影响。\n",
    "\n",
    "方案三：\n",
    "\n",
    "更极端一些，把老笔记也分为两个组，对照组、实验组，这样做就相当于切成了2个APP，如果希望实验结果精准，这种方案是最优的，如果发现AB测试指标涨了，推全之后也会涨这么多，但这种方案不太实际可行。切成2个APP，内容池小了一半，会严重损害用户体验，消费指标一定会大跌，为了做个AB测试，严重损害了公司业务，这个代价不太划算。\n",
    "\n",
    "总结：\n",
    "\n",
    "冷启动的AB测试既要做作者侧实验观测作者发布指标，也要做用户侧实验观测消费指标，这是因为冷启动至少有2个目标，激励作者发布和让用户满意。每种AB测试的方案都有缺点，设计AB测试方案的时候，要问自己几个问题，从而判断自己的实验设计有没有缺陷：1. 新笔记分为实验组和对照组，两组新笔记会不会抢流量？2. 新笔记和老笔记是怎样抢流量的？AB测试的时候是怎么抢的，推全之后是怎么抢的？如果AB测试和推全之后抢流量的方式发生了变化，那么AB测试的结果可能会不准。3. 如果同时隔离笔记和用户，会不会让内容池变小？如果变小肯定会影响推荐效果，用户体验变差，也就是说为了做个AB测试影响了大盘，损害了公司业务。4. 如果对新笔记做保量，比如保100次曝光，会发生什么？如果笔记从实验组那里获得了很多曝光，比如获得了80次曝光，笔记就不容易出现在对照组那里，因为只需要从对照组那里获得20词曝光而已，就能达到保量目标，如果有保量，得仔细思考一下，实验的准确性会不会受保量的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b7a8e",
   "metadata": {},
   "source": [
    "LR离散特征较好，连续特征不好；GBDT连续特征较好，离散特征不好；GBDT+LR 好于单个，但输入都是稠密特征，记忆能力较差，所以又引入支持高稠密特征的FM模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
